{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"<code>jinko</code> programming documentation","text":"<p>Welcome to the documentation regarding the jinko programming language!</p> <p>You can find information on how to use the language as well as documentation about the standard library. A development guide is also included for contributors.</p>"},{"location":"#sections","title":"Sections","text":"<ul> <li>Language documentation: How to program in jinko</li> <li>Standard library: Developer documentation for the standard library</li> </ul>"},{"location":"#contact","title":"Contact","text":"<ul> <li>Matrix server</li> </ul> <p>Feel free to ask about anything on our #dev and #off-topic channels. We're aware that the documentation might not be in a clear enough state for new programmers!</p>"},{"location":"#links","title":"Links","text":"<ul> <li>Repository</li> <li>GitHub organization</li> </ul>"},{"location":"language/","title":"The jinko programming language","text":"<p><code>jinko</code> is an interpreted strongly and statically typed programming language. It relies on a strong typechecker and a low amount of concepts in order to keep scripts simple and correct.</p> <p>The goal of <code>jinko</code> is to stay simple: The language specification should stay tiny, with few keywords and few builtins. If possible, a lot of the functionality should be baked-in the standard library: This helps in having multiple possible implementations, which could implement a complete language by respecting a small specification. The standard library should rely on the type system as much as possible.</p> <p>This chapter contains information regarding how to program in <code>jinko</code>. Inside, you will find out how the type-system works, how it compares to other languages, how to do conditionals, for loops, or any other language construct.</p> <p>Keep in mind that <code>jinko</code> is still being developed: If something in this chapter is not clear enough or seems invalid, please let us know via a github issue or on our matrix chat.</p> <ul> <li>Types </li> <li>Variables</li> <li>Functions</li> <li>Conditionals</li> <li>Loops</li> <li>Blocks</li> <li>Code inclusion</li> </ul>"},{"location":"language/variables/","title":"Variables","text":""},{"location":"language/variables/#declaring-variables","title":"Declaring variables","text":"<pre><code>a = 15;\n</code></pre>"},{"location":"language/variables/#type-hinting","title":"Type hinting","text":"<pre><code>a: int = 15;\n</code></pre>"},{"location":"language/variables/#using-variables","title":"Using variables","text":""},{"location":"language/types/0_builtin_types/","title":"Built-in types","text":"<p>4 types are baked in the interpreter: <code>bool</code>, <code>int</code>, <code>float</code>, <code>string</code> and <code>char</code>. Each of these types has associated functions, which can be found in the standard library.</p> <ul> <li><code>int</code></li> </ul> <p><code>int</code> represents all sorts of signed integers. It is 64-bits wide, and can contain values from <code>-9 223 372 036 854 775 808</code> to <code>9 223 372 036 854 775 807</code>.</p> <ul> <li><code>float</code></li> </ul> <p><code>float</code> is a double-precision floating point number, similar to C's <code>double</code> or Rust's <code>f64</code>.</p> <ul> <li><code>bool</code></li> </ul> <p>At the moment, booleans are still builtin types with two associated keywords: <code>true</code> and <code>false</code>. Thanks to this chapter, you'll soon see why we plan on replacing it with the following in our standard library.</p> <pre><code>type true;\ntype false;\ntype bool(true | false);\n</code></pre> <ul> <li><code>char</code></li> </ul> <p><code>char</code>s are simple UTF-8 characters.</p> <ul> <li><code>string</code></li> </ul> <p>In <code>jinko</code>, strings are not simply arrays of characters, at least for now. We rely on Rust's <code>String</code> implementation in order to have the <code>string</code> type. This is subject to change, and will obviously be different once the interpreter is self-hosted.</p>"},{"location":"language/types/1_custom_types/","title":"Custom types in jinko","text":""},{"location":"language/types/1_custom_types/#declaration","title":"Declaration","text":""},{"location":"language/types/1_custom_types/#instantiation","title":"Instantiation","text":""},{"location":"language/types/2_contract/","title":"Type obligations","text":"<p>When defining a custom type, you may wish for your users to respect certain obligations. Say for example, that you wish to only deal with even numbers. You would define an <code>Even</code> type, containing its associated integer.</p> <pre><code>type Even(value: int);\n</code></pre> <p>This isn't really useful, since you're able to do the following:</p> <pre><code>two = Even(value: 3);\n</code></pre> <p>One solution to this would be to hide the instantiation of this type behind a function, and telling the user to be very careful and only call this function to create a new even number:</p> <pre><code>func even(from: int) -&gt; Maybe[Even] {\n    if from.mod(2) == 0 {\n        Even(value: from)\n    } else {\n        Nothing\n    }\n}\n</code></pre> <p>which forces your users to make sure they've received a correct <code>Even</code> and not an instance of <code>Nothing</code>.</p> <p>Since this behavior is extremely useful (ranged integers, specific values out of multiple possibilities, safety checks...), <code>jinko</code> offers a keyword to help define conditions that users must uphold when instantiating types.</p> <p>The standard library uses those type obligations in order to make calls to foreign functions safer: For example, when wrapping the standard C library, you will often face two situations when dealing with pointers:</p> <ul> <li>A null pointer is a valid value, and will be checked for (<code>write(3)</code>)</li> <li>A null pointer is invalid, and will not be checked for: The function might crash (<code>qsort(3)</code>)</li> </ul> <p>You can easily represent these two types of pointers in <code>jinko</code>: One is simply a pointer, and the other a non-null pointer. These are not novel concepts: They've been in various programming languages. However, <code>jinko</code>'s type system helps in making sure that a <code>Pointer</code> is never given to a function expecting a <code>NonNullPointer</code>, while still easily allowing you to convert a <code>NonNullPointer</code> into a <code>Pointer</code>.</p>"},{"location":"language/types/2_contract/#defining-type-obligations","title":"Defining type obligations","text":"<p>You can define a type obligation by adding the <code>with</code> keyword to your type declaration:</p> <pre><code>type Even(value: int) with value.mod(2) == 0;\n</code></pre> <p>The syntax is as follows:</p> <pre><code>'type' &lt;name&gt; '(' &lt;fields&gt; ')' 'with' &lt;boolean_expr&gt; ';'\n</code></pre> <p>A boolean expression can be any <code>jinko</code> expression: It will be typechecked to make sure that it returns a boolean. This means that you can have multiple checks on a single type:</p> <pre><code>type PositiveEven(value: int) with value.mod(2) == 0 &amp;&amp; value &gt; 0;\n\n// or slightly more verbose\n\ntype PositiveEven(value: int) with {\n    mod_check = value.mod(2) == 0;\n    pos_check = value &gt; 0;\n\n    mod_check &amp;&amp; pos_check\n}\n</code></pre>"},{"location":"language/types/2_contract/#instantiating-types-with-type-obligations","title":"Instantiating types with type obligations","text":"<p>When creating such a type instance, it is important to note to the user that failure might occur. This is why instantiating those values will not directly return the type <code>T</code>, but <code>T</code> wrapped in a <code>Maybe</code>:</p> <pre><code>a: Even = Even(value: 2); // type error!\n// `a` is actually of the type `Maybe[Even]`\n</code></pre> <p>We must handle the optional type to make sure that we deal with the failure case appropriately:</p> <pre><code>a0: Even = Even(value: 2).unpack(); // if we know it cannot fail\na1: Even = Even(value: 2).try(); // to propagate the error to the caller\n</code></pre> <p>In the case that the condition fails, an instance of <code>Nothing</code> will be returned.</p> <pre><code>assert(Even(value: 3).is_nothing()) // true\n</code></pre>"},{"location":"language/types/2_contract/#making-our-safe-ffi-pointer-types","title":"Making our safe FFI pointer types","text":"<p>As explained above, the problem is as follows: Some pointers are allowed to be null pointers, while some pointers cannot.</p> <p>Let's take the following C example, which sorts an array of integers:</p> <pre><code>#include &lt;assert.h&gt;\n#include &lt;stdbool.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\nint icmp(const void *l_v, const void *r_v) {\n  int l = (int)(unsigned long)l_v;\n  int r = (int)(unsigned long)r_v;\n\n  return r &gt; l ? 1 : r &lt; l ? -1 : 0;\n}\n\nint main(void) {\n  int *ptr = NULL;\n\n  int array[5] = {0, 1, 2, 3, 4};\n\n  qsort(array, 5, sizeof(int), icmp);\n\n  for (size_t i = 0; i &lt; 5; i++)\n    printf(\"array[%lu] = %d\\n\", i, array[i]);\n\n  // No comparison function here\n  qsort(array, 5, sizeof(int), NULL);\n\n  return 0;\n}\n</code></pre> <p>In the case that we forget to give a valid comparison function to <code>qsort</code>, the program will crash.</p> <p>When wrapping the <code>qsort</code> function in <code>jinko</code>, we might thus want to mark the last argument of the function as a <code>NonNullPointer</code>:</p> <pre><code>link_with(\"libc.so.6\");\n\next func qsort(base: NonNullPointer, nmemb: int, size: int, cmp: NonNullPointer);\n</code></pre> <p>This will prevent <code>jinko</code> code to ever pass a <code>NULL</code> pointer to the <code>qsort</code> function.</p> <pre><code>type RawPointer(raw_value: int); // ...\ntype NonNullPointer(ptr: RawPointer) with ptr.raw_value != 0;\n</code></pre> <p>Since we may want to give <code>NonNullPointer</code>s to functions that expect a regular, nullable <code>Pointer</code>, we can use multi-types to defined the <code>Pointer</code> type:</p> <pre><code>type Pointer(ptr: NonNullPointer | RawPointer);\n</code></pre> <p>Any value of type <code>Pointer</code> will thus be able to be created by upcasting a <code>NonNullPointer</code> or a <code>RawPointer</code>.</p>"},{"location":"language/types/multi_types/","title":"Multi types","text":""},{"location":"language/types/multi_types/#defining-multi-types","title":"Defining multi-types","text":""},{"location":"language/types/multi_types/#upcasting","title":"Upcasting","text":""},{"location":"standard-library/","title":"Documentation","text":"<p>The documentation is also available inside the <code>stdlib</code>'s source code. This is a rendered version which contains the same exact content.</p>"},{"location":"standard-library/#stdlib-modules","title":"stdlib modules","text":""},{"location":"writeups/0000-design/","title":"WU0000: Design","text":"<p>This document describes some of the choices made when developing jinko, as well as some implementation choices</p>"},{"location":"writeups/0000-design/#stmts-and-exprs","title":"Stmts and Exprs","text":"<p>There are two types of instructions in jinko: Those returning the equivalent of <code>void</code>, or <code>{}</code>, such as a variable assignation:</p> <pre><code>x = 12; // Returns \"void\"\n\nfunc void_func() { // Returns nothing\n}\n\nvoid_func(); // Thus a statement as well\n</code></pre> <p>And those returning any other type, which must not be ignored. For example, constant expressions or non-void function calls:</p> <pre><code>func return_x(int: x) -&gt; int {\n    x // Returns an integer. Notice the lack of semicolon\n}\n\nfunc return_func(int: x) -&gt; func(int) -&gt; int {\n    l = func lambda(int: x) -&gt; int {\n        x + 1\n    };\n\n    l\n} // This returns a lambda taking an int as argument and returning an int\n</code></pre> <p>Statements are void, while Expressions return something. You cannot ignore a non-void return value.</p>"},{"location":"writeups/0000-design/#unit-tests","title":"Unit tests","text":"<p>Embedding unit testing in a language relies on using an \"attribute-like\" syntax. For example, in Java you can do the following by using a library, JUnit, which itself uses attributes (@ syntax).</p> <pre><code>@Test\npublic void something_something_factory_bean_sprout() {\n    assertEquals(something(), something_else());\n}\n</code></pre> <p>In rust, attributes (or tags) use the #[syntax]. Unit tests are embedded directly into the language without the need for external libraries.</p> <pre><code>#[test]\nfn something_in_rust() {\n    assert_eq!(something(), something_else());\n}\n</code></pre> <p>In jinko, test functions require no attribute (not that it's any better than using an attribute, it's just simpler for the interpreter).</p> <pre><code>test something_but_in_jinko() {\n    assert_eq(something(), something_else());\n}\n</code></pre> <p>Mocking is done similarly, by using the <code>mock</code> keyword</p> <pre><code>/* This will mock the function something() */\nmock something() {\n    /* Mocking */\n}\n</code></pre>"},{"location":"writeups/0000-design/#choosing-between-func-and-fn","title":"Choosing between func and fn","text":"<p>jinko uses three keywords to define \"functions\": * <code>test</code> which are unit tests * <code>mock</code> which are function mocks * <code>func</code> which is for functions and procedures</p> <p>(Procedures return <code>Nothing</code>, while Functions return <code>Something</code>)</p> <p><code>func</code> was chosen over <code>fn</code> because this way, it looks pretty when next to a <code>test</code> or a <code>mock</code> :)</p>"},{"location":"writeups/0000-design/#the-instruction-struct","title":"The <code>Instruction</code> struct","text":"<p>Instructions are a central part of Jinko. A jinko program is composed of instructions and functions, which themselves are instructions. Instructions can be either Statements or Expressions</p> <p><pre><code>x = 12; // Stmt\nx // Expr\n</code></pre> -&gt; This jinko code simply assigns a variable x and returns it. If you execute it, the exit-code will be the value assigned to <code>x</code>. In that case, 12</p> <p>An instruction needs to contain \"spacial\" information (Where is it in the file ? In what file ?), source (the actual source code, for errors), and a Statement or an Expression to execute.</p>"},{"location":"writeups/0000-design/#importing-other-source-files","title":"Importing other source files","text":"<p>Since jinko scripts are simple scripts a la Python, where there is no main functions, importing simply works by \"copy/pasting\" other source files. There is no distinction between headers and source files, so it's a bit different from C's preprocessor for example. However, the syntax is similar</p> <pre><code>incl other_script;\n/* Functions, Variables in other_script are imported. They're now named\nother_script::&lt;function_name&gt;, other_script::&lt;var_name&gt; and so on */\n</code></pre> <p>There is no way to remove the usage of <code>&lt;source_name&gt;::</code>. This is the cause of some programming issues in C++, C# and other languages with similar features.</p> <p>You can only import an external source once per program. This way, no circular dependencies are created.</p> <p>To separate sources with the same name, for example from multiple directories, you can use the <code>as</code> syntax</p> <pre><code>// Wrong\nincl dir0::source0;\nincl dir1::source0;\n\n/* Both sources would have the same name. This is an error */\n\n// Good\nincl dir0::source0 as dir0_source0;\nincl dir1::source0 as dir1_source0;\n/* Now, dir0::source0 functions are named dir0_source0::&lt;function_name&gt; and so on */\n</code></pre> <p>For now, you can also include directories:</p> <pre><code>/*\n|_ main.jk\n|_ std/\n    |_ lib.jk       // includes option.jk, result.jk maybe, etc\n    |_ option.jk\n    |_ result.jk\n*/\n\n```rust\nincl std // Actually includes std/lib.jk\n</code></pre> <p>I'm not entirely happy with this design yet. It's obviously open to discussion and changes.</p>"},{"location":"writeups/0000-design/#garbage-collection","title":"Garbage collection","text":"<p>Memory allocation and collection is done via reference counting. This implies lower stress on the hardware used to run the program, and is easier to implement, thus keeping jinko simpler. However, this causes issues when an instance references itself, thus creating memory leaks.</p>"},{"location":"writeups/0000-design/#ffi","title":"FFI","text":"<p>The idea is to mark functions from external shared libraries with the <code>ext</code> keyword.</p> <pre><code>ext func add(lhs: int, rhs: int) -&gt; int; // This function isn't defined in jinko\n</code></pre> <p>Calling <code>add()</code> will actually make a call into a native-code function, for example one written in Rust, C or C++. Adjustments need to be done on the native side of things in order to allow name resolution</p>"},{"location":"writeups/0000-design/#nullable-types","title":"Nullable types","text":"<p>In Rust, types are not nullable. There is no way (in the safe subset of the language at least) to return <code>NULL</code> as a value. However, the <code>Option</code> type exists: You can either return <code>Some(value)</code> or <code>None</code> in case something went wrong. You also have to handle both cases when using those Option types. In languages such as Zig (I think) or Dart (soon), some types can be \"nullable\". By annotating the type with a question mark, you can indicate that the value might be null. For example, <code>String</code> needs to be a valid string, but <code>String?</code> can be a valid string or NULL. These two approaches do not exactly serve the same purpose. However, they are useful when it comes to error handling, as well as the possibility of not having something. In C, you are constrained to use NULL. Every pointer is \"nullable\", and therefore you always have to check for NULL. In Dart and Zig, you only have to check for NULL if the type is nullable. In Rust, you have to check your option types or <code>unwrap()</code> on them, which will cause a panic in case of a <code>None</code> (a bit equivalent to segfaulting on NULL, but less sneaky and way less vulnerable).</p> <p>While these two approaches both have advantages and inconvenient, the Rust approach is, in my opinion for Jinko, significantly better for a simple reason: Even if Options are part of the standard library and \"included\" by default, they do not rely on some obscure compiler magic: They are just a type. Therefore, they are being understood by the compiler as just a type. And I think that keeping <code>jinko</code> simple also means keeping the interpreter simple. Therefore, I think that simply using <code>Option</code>s (or some other nomenclature) would be best.</p>"},{"location":"writeups/0000-design/#the-interpreter","title":"The interpreter","text":"<p>The jinko interpreter should keep track of variables and functions. Therefore, at least two hashmaps are required, one for variables and one for functions. Each of these elements need to have a unique name to identify them.</p>"},{"location":"writeups/0000-design/#structure-types","title":"Structure Types","text":"<p>Allowing user defined types makes for cleaner as well as stricter code. One thing that jinko really has to focus about is \"zero-cost types\", as in custom types that englobe a single, other type without penalty. In the mean time, the interpreter should also focus on simple parsing and fonctionality. Let's split this section in two:</p>"},{"location":"writeups/0000-design/#simple-type-parsing","title":"Simple type parsing","text":"<p>In order to keep the parsing simple, as much code as possible should be reused. At this point, the parser is already around 1500 lines big, and that's big enough. Types declarations are similar to function declarations: They have a name, take arguments. Type instantiations, however are quite different. Let's examine a custom types in C and its instantiation:</p> <pre><code>struct custom_type {\n    int int_value;\n    char some_character;\n    float f;\n};\n\n// And to initialize it, one way is to do the following\nstruct custom_type value = { .int_value = 4, .char = 'J', .float = 27.07};\n</code></pre> <p>This is similar to creating and calling a function, only that the syntax differs. I believe jinko could keep the same syntax for both custom types and custom functions, as they aim to achieve the same \"kind\" of result: A custom, user-made behavior that produces cleaner and more readable code.</p> <p>Thus, the following syntax should be adopted at first:</p> <pre><code>// This is similar to a function declaration, without a block and with a ``type`` instead of ``fn``\ntype CustomType(int_value: int, some_character: char, f: float);\n\n// Let's create one\nvalue = CustomType(int_value: 4, some_character: 'J', f: 27.07);\n</code></pre> <p>If your types get too big, then just like function definitions, multilines are supported.</p> <pre><code>type CustomType(\n    int_value: int,\n    some_character: char,\n    f: float,\n);\n</code></pre> <p>The only difference between a function definition and a type definition is the keyword: <code>type</code> or <code>func</code> and no block of code for the type instantiation.</p> <p>Type instantiations use the <code>:</code> token to associate a value with a field, while function calls do not use any token. For optional/named arguments, function calls use the <code>=</code> token</p>"},{"location":"writeups/0000-design/#methods-and-functions-in-jinko","title":"Methods and functions in Jinko","text":"<p>Let's say you define your custom type in C. If you do \"object oriented C\", you'll probably end up with the following:</p> <pre><code>/* Simple linked list node */\nstruct ll {\n    int value;\n    struct ll *next;\n};\n\n/* Create a new node */\nstruct ll *ll_new(int value, struct ll *next);\n\n/* Destroy a previously created node */\nvoid ll_del(struct ll *head);\n\n/* Get the next node */\nstruct ll *ll_next(struct ll *node);\n\n/* Get the value from the node */\nint ll_value(struct ll *node);\n\n/* Push some node to the list */\nvoid ll_push(struct ll *node, struct ll *next);\n\n/* Implementation is not important */\n\nint main(void) {\n    // Create our head\n    struct ll *last = ll_new(3, NULL);\n    struct ll *mid = ll_new(2, last);\n    struct ll *head = ll_new(1, mid);\n\n    struct ll *rand = ll_new(67, NULL);\n    ll_push(head, rand);\n\n    // Make sure the positions and values are correct\n    assert(ll_value(ll_next(head)) == 2);\n\n    // We're done with the list\n    ll_del(head);\n}\n</code></pre> <p>The \"object oriented\" approach does not really work in C, and is cumbersome. Compare it to any actual OOP language, where we could do <code>head.del()</code>, or <code>head.next().value()</code>.</p> <p>However, the object oriented approach brings in a lot of complexity, too much for jinko. A struct model, in a C way should be prefered. But that doesn't mean we can't add some syntactic sugar to it.</p> <p>Let's consider a custom type with its \"methods\" and a simple function.</p> <pre><code>// There's already a \"default constructor\", so we don't need to define new(). Also, there\n// is no NULL in jinko\ntype LinkedList(value: int, next: Option&lt;LinkedList&gt;);\n\nfunc del(head: LinkedList) {\n    /* Walk the whole list, deleting stuff as it comes */\n}\n\nfunc value(node: LinkedList) -&gt; int {\n    node.value\n}\n\nfunc next(node: LinkedList) -&gt; LinkedList {\n    node.next\n}\n\nfunc push(node: LinkedList, next: LinkedList) {\n    /* Some code to add next to the end of the list or whatever */\n}\n\nlast = LinkedList(3, None);\nmid = LinkedList(2, Some(last));\nhead = LinkedList(1, Some(mid));\n\nhead.push(LinkedList(67, None));\n\n/* Or ... */\n\npush(head, LinkedList(67, None));\n\nassert_eq(head.next().value(), 2);\n\n/* Or ... */\n\nassert_eq(value(next(head)), 2);\n\n/* We're done with the list */\n\nhead.del();\n</code></pre> <p>Both calling methods are valid. In the end, to keep things simple, the first argument will always act similarly to <code>self</code> in Rust, or <code>this</code> in most OOP languages. This also means that the following is possible</p> <pre><code>func add(a: int, b: int) -&gt; {\n    a + b\n}\n\n12.add(15);\nadd(12, 15);\n</code></pre> <p>So the concept of methods doesn't really exist in Jinko. The calling method is just syntactic sugar over regular function calling.</p>"},{"location":"writeups/0000-design/#no-cost-custom-types","title":"No-cost custom types","text":"<p>Let's say you're using an API, and using some complex custom made function. For example, <code>add_friend</code>, which takes a last name, a first name, and a nickname. Let's say you're not using an IDE or a language server: You remember the function name, but not the order of the arguments: Is it <code>add_friend(first_name, name, nickname)</code>? <code>add_friend(nickname, first_name, name)</code>? If the API was designed by a japanese coder, maybe it's <code>add_friend(name, first_name, nickname)</code>?</p> <p>There is no way to know without checking the documentation. Now, this is good, since it forces you to check the documentation. But we can also enforce type safety and data safety through the interpreter.</p> <pre><code>// The friend type, that already existed\ntype Friend(/* Some values */);\n\n// Define three \"custom\" types\ntype Name(the_name: str);\ntype FirstName(value: str);\ntype Nickname(hidden: str);\n\n// And define the API function like so:\nfunc add_friend(name: Name, f_name: FirstName, n_name: Nickname) -&gt; Friend {\n    /* Some code */\n}\n</code></pre>"},{"location":"writeups/0000-design/#generics","title":"Generics","text":"<p>Generics rely on the use of brackets so that the parser can easily differentiate between a generic use/declaration (<code>A&lt;T&gt;</code>) versus a variable comparison (<code>A &lt; T</code>) without any sort of lookahead. Thus, the following in C++</p> <pre><code>std::vector&lt;std::unordered_map&lt;std::string, int&gt;&gt; map = ...;\n</code></pre> <p>would become in jinko</p> <pre><code>map: Vec[Map[string, int]] = ...; \n</code></pre> <p>Likewise, the following Rust code</p> <pre><code>fn takes_result(r: Result&lt;String, SomeErrorType&gt;) {}\n</code></pre> <p>becomes</p> <pre><code>func takes_result(r: Result[string, SomeErrorType]) {}\n</code></pre> <p>This syntax is similar to scala's generics, which are quite nice to use.</p> <p>Generics, just like function parameters, should be able to take a default value, which could be specified by name.</p> <pre><code>type BaseError(inner: string);\n\ntype Ok[T](T);\ntype Err[T](T);\ntype Result[T = void, E = BaseError](Ok[T], Err[E]);\n\n// We can avoid typing `Result` by using type promotion but w/e, this is for\n// the example's sake\nok_0 = Result[int](Ok(15)); // E defaults to BaseError\nok_1 = Result[int, string](Ok(15));\nok_2 = Result[int, string](Err(\"oops\"));\nok_4 = Result[T = int, string](Err(\"oops\"));\nok_5 = Result[T = int, E = string](Err(\"oops\"));\nok_6 = Result[E = bool](Err(false)); // T defaults to void\n</code></pre>"},{"location":"writeups/0001-error-handling/","title":"WU0001: Error handling in jinko","text":"<p>This document should not cover the usage of <code>Maybe[T]</code> as that has been previously established.</p>"},{"location":"writeups/0001-error-handling/#the-error-type","title":"The <code>Error</code> type","text":"<pre><code>type Error[T = string](from: T);\n\n/// The error type is generic, as long as the contained type\n//implements the `as_error()` method\nfn emit[T](err: Error[T]) {\n    println_err(err.from.as_error())\n}\n\n// Specialization for the default implementation\nfn emit[T: string](err: Error[string]) {\n    println_err(err.from)\n}\n</code></pre>"},{"location":"writeups/0001-error-handling/#without-a-result-type","title":"Without a <code>Result</code> type","text":"<pre><code>// We can use the default `string` type contained in an `Error`\n\n// Fails if a division by 0 is performed\nfunc div_can_fail(lhs: int, rhs: int) -&gt; int | Error {\n    if rhs == 0 {\n        Error(from: \"Attempting division by 0\")\n    } else {\n        lhs / rhs\n    }\n}\n\nswitch div_can_fail(165, 0) {\n    value: int =&gt; println(\"Result is {value}, yipee\"),\n    e: Error =&gt; e.emit(),\n}\n\n// We can also use a complex type as the error's inner\n// type\ntype DivError;\n\nfn as_error(err: DivError) -&gt; string {\n    \"Division error\"\n}\n\nfunc div_can_fail2(lhs: int, rhs: int) -&gt; int | Error[DivError] {\n    if rhs == 0 {\n        Error(from: DivError)\n    } else {\n        lhs / rhs\n    }\n}\n</code></pre>"},{"location":"writeups/0001-error-handling/#with-a-result-type","title":"With a <code>Result</code> type","text":"<pre><code>type Result[T, E = string](Ok[T] | Error[E]);\n\n// Using the default string as error type again\nfunc div_can_fail3(lhs: int, rhs: int) -&gt; Result[int] {\n    if rhs == 0 {\n        Error(from: \"Attempting division by 0\")\n    } else {\n        Ok(with: lhs / rhs)\n    }\n}\n\nswitch div_can_fail(165, 0) {\n    value: Ok =&gt; println(\"Result is {value.get()}, yipee\"),\n    e: Error =&gt; e.emit(),\n}\n</code></pre>"},{"location":"writeups/0001-error-handling/#propagating-the-errors","title":"Propagating the errors","text":"<p>Since <code>jinko</code> currently does not have a concept of postfix operators, we will need to rely on interpreter magic to propagate errors properly.</p> <pre><code>// Assuming we have the same Result type before\n\nfunc try[T, E](result: Result[T, E]) -&gt; T {\n    switch result {\n          ok: Ok =&gt; ok.get(),\n          err: Error =&gt; Jinko.caller().return_with(err), // return *from* the caller\n    }\n}\n\nfunc faillible_fn() -&gt; Result[int, DivError] {\n    Ok(with: 3);\n}\n\nfunc another_faillible_fn() -&gt; Result[int, DivError] {\n    Err(from: DivError);\n}\n\nfunc propagate_result() -&gt; Result[int, DivError] {\n    a = faillible_fn().try();\n    //  ^ Ok(int)      ^ int\n    b = another_faillible_fn().try();\n    //  ^ Err(...)\n    // \n    // this will cause a return from the current function: try's caller\n\n    // This instruction will never be reached, since b will always\n    // be an Err[] and cause an early return. If b was valid, we would otherwise\n    // just have extracted the integer and computed an addition here\n    Ok(with: a + b)\n}\n</code></pre>"},{"location":"writeups/0002-generics/","title":"WU0002: Canonicalization and generics in jinko","text":""},{"location":"writeups/0002-generics/#rules","title":"Rules","text":"<ul> <li>Each block is its own subgraph</li> <li>Each line of the graph corresponds to an instruction</li> <li>Each arrow is an assignment<ul> <li>statements simply have their return value \"ignored\" in this representation</li> <li><code>_ -&gt; stmt</code></li> </ul> </li> <li>Function declaration<ul> <li>syntax: <code>&lt;func_name&gt; -&gt; [ &lt;arg&gt; [, &lt;arg&gt;]* ] -&gt; &lt;ret_val&gt;</code></li> <li>examples: <code>println -&gt; s -&gt;</code>, <code>takes_nothing -&gt; -&gt;</code>, <code>return_value -&gt; -&gt; x</code></li> <li>macro: <pre><code>($f_name:ident -&gt; $($arg:ident),* -&gt; $($ret_type:ident)?)\n</code></pre></li> </ul> </li> <li>Function call<ul> <li>syntax: <code>&lt;func_name&gt; &lt;- [ &lt;arg&gt; [, &lt;arg&gt;]* ]</code></li> <li>examples: <code>println &lt;- 'hey'</code>, <code>takes_nothing &lt;-</code>, <code>return_value &lt;-</code></li> <li>macro: <pre><code>($f_name:ident &lt;- $($arg:ident),*)\n</code></pre></li> </ul> </li> </ul>"},{"location":"writeups/0002-generics/#example-graph","title":"Example graph","text":"<pre><code>func f(a: int, b: int) -&gt; int {\n    print(a);\n    a + b\n}\n</code></pre> <pre><code>flowchart TD;\n    subgraph f[f -&gt; a, b -&gt; x];\n        direction LR;\n        a --&gt; a_init;\n        b --&gt; b_init;\n        x --&gt; f_block;\n        subgraph f_block[f_block -&gt; block_x]\n            direction LR;\n            _ --&gt; print[print &lt;- a]\n            block_x --&gt; add[add &lt;- a, b]\n        end\n    end</code></pre>"},{"location":"writeups/0002-generics/#problem","title":"Problem","text":"<p>Generating specialized function during generic expansion [1] causes specialized functions to be dropped when exiting the current typechecking scope.</p> <p>Specialized functions (i.e. expanded generics) need to be generated and put in the outermost scopemap in order to not get deleted when exiting the current scope.</p> <p>[1]: A generic function can be declared and will be expanded right after typechecking <pre><code>// Original code\nfunc quack[D](instance: D) -&gt; string {\n    instance.get_quack_str()\n}\n\ni_quack = 15.quack();\n\ntype Duck;\nfn get_quack_str(d: Duck) -&gt; string { \"quack\" }\n\nr_quack = Duck.quack();\n</code></pre> <pre><code>// after typechecking\nfunc quack[D](instance: D) -&gt; string {\n    instance.get_quack_str()\n}\n\ni_quack = 15.quack();\n// 15 &lt;- int\n// We want quack[int](instance: int) -&gt; string\n\ntype Duck;\nfn get_quack_str(d: Duck) -&gt; string { \"quack\" }\n\nr_quack = Duck.quack();\n// Duck &lt;- Duck\n// We want quack[Duck](instance: Duck) -&gt; string\n</code></pre> <pre><code>// specialization/monomorphization\nfunc quack[D](instance: D) -&gt; string {\n    instance.get_quack_str()\n}\n\nfunc quack+int(instance: int) -&gt; string {\n    instance.get_quack_str()\n} // type error\n\nfunc quack+Duck(instance: Duck) -&gt; string {\n    instance.get_quack_str()\n} // Okay!\n\ni_quack = quack[int](15);\n\ntype Duck;\nfn get_quack_str(d: Duck) -&gt; string { \"quack\" }\n\nr_quack = quack[Duck](Duck);\n</code></pre></p> <p>Sadly, this process happens during typechecking which contains a different scopemap from the execution context. What we can do is return a vector of generated nodes after the typechecking phase and insert those in the execution context. They however need proper canonicalization, which we'll discuss after.</p> <p><pre><code>flowchart TD;\n    subgraph entry\n        direction LR;\n        subgraph quack_gen[quack+D -&gt; instance -&gt; s];\n            direction LR;\n            instance --&gt; instance_init;\n            s --&gt; f_block\n            subgraph f_block[quack_block+D -&gt; block_s]\n                direction LR;\n                block_s --&gt; call[get_quack_str &lt;- instance]\n            end\n        end\n\n        i_quack --&gt; quack_15[quack &lt;- 15];\n        duck --&gt; duck_insantiation[#instantiate &lt;- Duck];\n        r_quack --&gt; quack_duck[quack &lt;- duck];\n    end</code></pre> end result: <pre><code>flowchart TD;\n    classDef specialized fill:#f9f,stroke:#333,stroke-width:4px;\n    class quack_Duck specialized;\n    class quack_int specialized;\n    subgraph entry\n        direction LR;\n        subgraph quack_gen[quack+D -&gt; instance -&gt; s];\n            direction LR;\n            instance --&gt; instance_init;\n            s --&gt; f_block\n            subgraph f_block[quack_block+D -&gt; block_s]\n                direction LR;\n                block_s --&gt; call[get_quack_str &lt;- instance]\n            end\n        end\n        subgraph quack_Duck[quack+Duck -&gt; instance+Duck -&gt; s+Duck];\n            direction LR;\n            Duck_instance[instance+Duck] --&gt; Duck_instance_init[instance+Duck_init];\n            Duck_s[s+Duck] --&gt; q_Duck_block\n            subgraph q_Duck_block[quack_block+Duck -&gt; block_s+Duck]\n                direction LR;\n                Duck_block_s[block_s+Duck] --&gt; Duck_call[get_quack_str &lt;- instance+Duck]\n            end\n        end\n        subgraph quack_int[quack+int -&gt; instance+int -&gt; s+int];\n            direction LR;\n            int_instance[instance+int] --&gt; int_instance_init[instance+int_init];\n            int_s[s+int] --&gt; q_int_block\n            subgraph q_int_block[quack_block+int -&gt; block_s+int]\n                direction LR;\n                int_block_s[block_s+int] --&gt; int_call[get_quack_str &lt;- instance+int]\n            end\n        end\n\n        i_quack --&gt; quack_15[quack+int &lt;- 15];\n        duck --&gt; duck_insantiation[#instantiate &lt;- Duck];\n        r_quack --&gt; call_quack_duck[quack+Duck &lt;- duck];\n    end</code></pre></p> <p>Since the end implementation of jinko will have proper paths and canonicalization, we cannot just generate these functions in the outermost scope, or else code like the following would break: <pre><code>func outer() {\n    func generic[T](lhs: T, rhs: T) -&gt; T { lhs + rhs }\n\n    a = generic(15, 14);\n    b = generic(5.4, 1.2);\n}\n\nfunc outer_again() {\n    func generic[T](lhs: T, rhs: T) -&gt; T { lhs - rhs }\n\n    a = generic(15, 14);\n    b = generic(5.4, 1.2);\n}\n</code></pre> As the specialized versions of <code>generic[T]</code> would both get generated in the outer scope, there would be a name collision. With canonicalization, the following would instead happen: <pre><code>func outer::generic[int](lhs: int, rhs: int) -&gt; int { lhs + rhs }\nfunc outer::generic[float](lhs: float, rhs: float) -&gt; float { lhs + rhs }\n\nfunc outer_again::generic[int](lhs: int, rhs: int) -&gt; int { lhs - rhs }\nfunc outer_again::generic[float](lhs: float, rhs: float) -&gt; float { lhs - rhs }\n\nfunc outer() {\n    func outer::generic[T](lhs: T, rhs: T) -&gt; T { lhs + rhs }\n\n    a = outer::generic(15, 14);\n    b = outer::generic(5.4, 1.2);\n}\n\nfunc outer_again() {\n    func outer_again::generic[T](lhs: T, rhs: T) -&gt; T { lhs - rhs }\n\n    a = outer_again::generic(15, 14);\n    b = outer_again::generic(5.4, 1.2);\n}\n</code></pre></p>"},{"location":"writeups/0002-generics/#generics-resolving","title":"Generics resolving","text":"<pre><code>flowchart TD;\n    generic_dec -----&gt; add_fn;\n    generic_cal[generic_call] --&gt; create_specialized_fn;\n    create_specialized_fn --&gt; resolve_generic[resolve_generic.with_type_map];\n    resolve_generic --&gt; typecheck_fn;\n    typecheck_fn --&gt; add_fn;</code></pre>"},{"location":"writeups/0002-generics/#generics-visitor","title":"Generics visitor","text":"<pre><code>// stdlib/vec.jk\ntype Vec[T](pointer: RawPointer);\n\nfunc create_vec[T]() -&gt; Vec[T] {\n    Vec[T](pointer: 0x0)\n}\n\nfunc push[T](v: Vec[T], elt: T) {\n    inner_init[T](v);\n    inner_grow[T](v, elt);\n}\n\n// main.jk\nv = create_vec[int]();\nv.push[int](14);\n</code></pre> <pre><code>// stdlib/vec.jk\ntype Vec[T](pointer: RawPointer);\n\nstruct TypeId {\n    id: Symbol, // T\n    generics: Vec&lt;TypeId&gt;, // []\n}\n\n// [T -&gt; int]\n\nstruct TypeId {\n    id: Symbol, // int\n    generics: Vec&lt;TypeId&gt;, // []\n}\n\n// add_specialized_node(SpecializedNode::Type(new_type));\n\nfunc create_vec+int() -&gt; Vec+int {\n    // [T -&gt; int]\n    Vec+int(pointer: RawPointer(0x0))\n}\n\nfunc create_vec[T]() -&gt; Vec[T] {\n    Vec[T](pointer: RawPointer(0x0))\n}\n\nfunc push+int(v: Vec+int, elt: int) {\n    inner_init+int(v);\n    inner_grow+int(v, elt);\n}\n\nfunc push[T](v: Vec[T], elt: T) {\n    inner_init[T](v);\n    inner_grow[T](v, elt);\n}\n\n// main.jk\nv = create_vec[int](); // OK\nv.push[int](14);\n</code></pre>"},{"location":"writeups/0002-generics/#generating-specialized-inner-nodes","title":"Generating specialized inner nodes","text":"<p>Nodes defined inside other nodes need to be handled as well</p> <pre><code>func id[T](input: T) -&gt; T {\n    func inner_id[T](input: T) -&gt; T {\n        input\n    };\n\n    inner_id[T](input)\n}\n\nid[int](15)\n</code></pre> <pre><code>func id+int(input: int) -&gt; int {\n    // Here in expansion phase\n}\n\nfunc id[T](input: T) -&gt; T {\n    func inner_id[T](input: T) -&gt; T {\n      input\n    };\n\n    inner_id[T](input)\n}\n\nid[int](15)\n</code></pre> <p>At this point in the expansion phase, we are in a <code>resolve-usages</code> phase. Meaning that we are simply trying to replace usages of generic types with their resolved counter points, changing from <code>T</code> to <code>int</code> in that case. However for the function declaration, we need to create a new definition using the resolved type: This is a <code>resolve-expand</code> phase of the expansion.</p> <p>We can maybe simply make it so that having a <code>FunctionDeclaration</code> in a <code>resolve-usages</code> context creates a new function and adds it as a specialized node</p> <pre><code>func inner_id+int(input: int) -&gt; int {\n    input\n}\n\nfunc id+int(input: int) -&gt; int {\n    // Remove the declaration node? Just declare it still?\n\n    inner_id+int(input)\n}\n\nfunc id[T](input: T) -&gt; T {\n    func inner_id[T](input: T) -&gt; T {\n      input\n    };\n\n    inner_id[T](input)\n}\n\nid[int](15)\n</code></pre>"},{"location":"writeups/0003-multi-types/","title":"WU0003: Sum types in jinko","text":"<p><code>jinko</code> has sum types which can be seen as an abstraction over a choice of multiple types at once. They are very useful when you are trying to represent data which might exist in multiple states, such as a valid state and an invalid one.</p> <p>This pattern is common in functional programming languages such as Rust or Haskell. In Rust, a sum type you'll often see used is the <code>Option</code> enum, whose definition looks something like this:</p> <pre><code>enum Option&lt;T&gt; {\n    Some(T),\n    None,\n}\n</code></pre> <p><code>jinko</code>'s sum types are similar to Rust's, with one key difference: in Rust, the variants of a sum type can only be used as enum variants - not as types or data instances themselves. They are a proxy to the information they contain. For example in Rust, you cannot pass a value of type <code>Some&lt;i64&gt;</code> to a function. Nor can you give it a <code>None</code>:</p> <pre><code>let a = Some(15); // we *know* this is the Some variant of an Option - not None\n\nfn foo(value: Some&lt;i32&gt; /* Invalid */) {}\nfn bar(value: Option&lt;i32&gt;) {} /* Ok */\n\nbar(a);\n</code></pre> <p>What you can do however, is give the information contained within those variants: in our case, either an integer, or... nothing:</p> <pre><code>let a = Some(15);\n\nfn works_on_some(value: i32) {}\nfn works_on_none(/* nothing */) {}\n\nmatch a {\n    Some(inner) =&gt; works_on_some(inner),\n    None =&gt; works_on_none(),\n} // Ok\n</code></pre> <p>This is fine for most cases, but gets annoying when creating your own sum types. Let's imagine we are trying to abstract types with lots of information, and want to represent the visitors of a zoo. This zoo accepts adults, children, assistance pets.</p> <pre><code>// a visitor can be a person, a child or an assistance pet\nenum Visitor {\n    Person,\n    Child,\n    AssistancePet,\n}\n</code></pre> <p>This is all fine and dandy, now let's add information to each of our variants:</p> <pre><code>enum AssistancePetKind {\n    Dog,\n    Cat,\n    Poney,\n    Rabbit,\n}\n\nenum Visitor {\n    Person {\n        name: String,\n        last_name: String,\n        age: u64,\n    },\n    Child {\n        /* children are anonymous in this zoo */\n        age: u64,\n        favorite_animal: String,\n        number_of_ice_cream_cones_consumed: u64,\n    },\n    AssistancePet {\n        kind: AssistancePetKind,\n        name: String,\n        harness: bool,\n    },\n}\n</code></pre> <p>if we were to have a function for each of our variants, the code would quickly get out of hand:</p> <pre><code>fn handle_person(name: &amp;str, last_name: &amp;str, age: u64) {}\nfn handle_child(age: u64, favorite_animal: &amp;str, ice_cream_cones: u64) {}\nfn handle_assistance_pet(kind: &amp;AssistancePetKind, name: &amp;str, harness: bool) {}\n\nmatch visitor /* of type Visitor */ {\n    Visitor::Person {\n        name,\n        last_name,\n        age,\n    } =&gt; handle_person(name, last_name, age),\n    Visitor::Child {\n        age,\n        favorite_animal,\n        number_of_ice_cream_cones_consumed,\n    } =&gt; handle_child(age, favorite_animal, number_of_ice_cream_cones_consumed),\n    Visitor::AssistancePet {\n        kind,\n        name,\n        harness,\n    } =&gt; handle_assistance_pet(kind, name, harness),\n}\n</code></pre> <p>There is a lot of repetition, and if we were to add more fields to our variants, we would need to change our function's declaration, our match pattern, as well as our match expression for that pattern. Furthermore, having too many arguments to a function hinders readability and causes a higher mental load when using said function.</p> <p>We can thus wrap our data in new external types to deal with:</p> <pre><code>struct Person {\n    name: String,\n    last_name: String,\n    age: u64,\n}\n\nstruct Child {\n    /* children are anonymous in this zoo */\n    age: u64,\n    favorite_animal: String,\n    number_of_ice_cream_cones_consumed: u64,\n}\n\nstruct AssistancePet {\n    kind: AssistancePetKind,\n    name: String,\n    harness: bool,\n}\n\nenum AssistancePetKind {\n    Dog,\n    Cat,\n    Poney,\n    Rabbit,\n}\n\nenum Visitor {\n    Person(Person),\n    Child(Child),\n    AssistancePet(AssistancePet),\n}\n\nfn handle_person(person: &amp;Person) {}\nfn handle_child(child: &amp;Child) {}\nfn handle_assistance_pet(pet: &amp;AssistancePet) {}\n\nmatch visitor /* of type Visitor */ {\n    Visitor::Person(p) =&gt; handle_person(p),\n    Visitor::Child(c) =&gt; handle_child(c),\n    Visitor::AssistancePet(pet) =&gt; handle_assistance_pet(pet),\n}\n</code></pre> <p>This is better, but we still have a lot of repetition. For each variant in our <code>Visitor</code> enum, we need to write the type of data we are keeping twice. Each variant cannot stand on its own as a meaningful value. This leads to some confusion but most importantly repetition.</p> <p>Let's look at the equivalent <code>jinko</code> code.</p> <pre><code>type Person(\n    name: string,\n    last_name: string,\n    age: int,\n);\n\ntype Child(\n    /* children are anonymous in this zoo */\n    age: int,\n    favorite_animal: string,\n    number_of_ice_cream_cones_consumed: int,\n);\n\ntype Dog;\ntype Cat;\ntype Poney;\ntype Rabbit;\n\ntype AssistancePet(\n    kind: Dog | Cat | Poney | Rabbit,\n    name: string,\n    harness: bool,\n);\n\ntype Visitor = Person | Child | AssistancePet;\n\nfunc handle_person(person: Person) {}\nfunc handle_child(child: Child) {}\nfunc handle_assistance_pet(pet: AssistancePet) {}\n\nswitch visitor /* of type Visitor */ {\n    p: Person -&gt; handle_person(p),\n    c: Child -&gt; handle_child(c),\n    pet: AssistancePet =&gt; handle_assistance_pet(pet),\n}\n</code></pre> <p>There is less repetition, and it is easier to add fields or variants to your types, as well as handle them later in your code. Let's have a look at their implementation as well as some of the design choices behind them.</p> <pre><code>type Red;\ntype Blue;\ntype Green(is_light: bool);\n\ntype Color = Red | Green | Blue;\n\nwhere color: Color = Green(is_light: true);\n</code></pre> <p>we instantiate a value of type <code>Green</code>, but assign it the type <code>Color</code>. This is fine and allowed, since the type <code>Green</code> is part of the multitype <code>Color</code>.</p> <p>On the other hand, this fails to typecheck:</p> <pre><code>where color: Red | Blue = Green(is_light: true);\n</code></pre>"},{"location":"writeups/0003-multi-types/#primitive-types","title":"Primitive types","text":"<p><code>jinko</code> has 5 primitive types, which are all sum-types. The easiest one to understand is <code>bool</code>, which simply represents either an instance of <code>true</code> or an instance of <code>false</code>.</p> <pre><code>type false;\ntype true;\ntype bool = false | true;\n</code></pre> <p>The <code>char</code> type can be seen in the same way - it is a sum type, which englobes all possible characters representable in <code>jinko</code>: 'a', 'b', 'c'... up until the last valid Unicode codepoint. This would take a lot of space to represent directly at the source level, so that type is implemented directly in the compiler. We use a similar technique for <code>int</code>, <code>float</code> and <code>string</code>.</p> <p>What this means is that each character, integer, floating-point number or string is a type in <code>jinko</code>.</p> <pre><code>where x: 15 = 15; // x is a value of type 15, whose value is 15\nwhere greet: \"hey\" = \"hey\";\nwhere greet2: \"hey\" = \"hello\"; // type error\n</code></pre> <p>On their own, these types are not very useful. They become interesting when we try and restrict the data our functions or types accept. We can imagine the following snippet, which goes in a cardinal direction based on a string input:</p> <pre><code>func advance_cardinal_direction(s: string) -&gt; Result {\n    switch s {\n        \"north\" -&gt; go_north(),\n        \"south\" -&gt; go_south(),\n        \"west\" -&gt; go_west(),\n        \"east\" -&gt; go_east(),\n        _ -&gt; Error(from: \"invalid cardinal direction: {s}\" ),\n    }\n}\n</code></pre> <p>or, we could also restrict this function to only accept valid cardinal directions at compile time:</p> <pre><code>// no need to return a Result - this function does not typecheck\n// if it does not have a proper cardinal direction as an argument\nfunc advance_cardinal_direction(s: \"north\" | \"south\" | \"west\" | \"east\") {\n    switch s {\n        \"north\" -&gt; go_north(),\n        \"south\" -&gt; go_south(),\n        \"west\" -&gt; go_west(),\n        \"east\" -&gt; go_east(),\n        // no error branch\n    }\n}\n</code></pre> <p>This transfers the responsibility to your library's users to sanitize their input and send your function proper datas. The same principle applies to types.</p>"},{"location":"writeups/0003-multi-types/#design","title":"Design","text":"<pre><code>where x = if condition { 15 } else { \"jinko\" };\n// x has type `int | string`\n\nwhere mut x = 15;\nx = \"jinko\";\n// type error\n// but the typechecker hints that you can specify x's type to work around this:\n\nwhere mut x: int | string = 15;\nx = \"jinko\";\n</code></pre>"},{"location":"writeups/0003-multi-types/#looking-at-a-few-common-types","title":"Looking at a few common types","text":"<pre><code>type Nothing;\ntype Maybe[T] = T | Nothing;\n\nfunc map[T, U](value: Maybe[T], mapper: func(T) -&gt; U) -&gt; Maybe[U] {\n    switch value {\n        inner: T -&gt; mapper(inner),\n        Nothing -&gt; Nothing,\n    }\n}\n\nfunc extract_or[T](value: Maybe[T], default: func() -&gt; T) -&gt; T {\n    switch value {\n        inner: T -&gt; inner,\n        Nothing -&gt; default(),\n    }\n}\n\nfunc checked_div(lhs: int, rhs: int) -&gt; Maybe[int] {\n    switch rhs {\n        0 -&gt; Nothing,\n        1 -&gt; lhs,\n        _ -&gt; lhs / rhs\n    }\n}\n\nfunc is_whitespace(c: char) -&gt; bool {\n    switch c {\n        '\\t' | ' ' -&gt; true,\n        weird: '\\r' | weird: '\\n' -&gt; {\n            eprintln(\"{weird} is one but it's weird right?\");\n            true\n        },\n        rest: _ -&gt; {\n            eprintln(\"got a non-whitespace char: {rest}\");\n            false,\n        }\n    }\n}\n</code></pre> <pre><code>switch_case := 'switch' expr '{' [ pattern '-&gt;' expr ]+ '}'\npattern     := ( pat_type | identifier ':' pat_type ) [ '|' pattern ]*\npat_type    := '_' | type\n</code></pre>"},{"location":"writeups/0003-multi-types/#limitations","title":"Limitations","text":"<ol> <li>Typechecking error when using <code>switch</code> on a float</li> </ol> <p>How to work around this? Have a safe float type which cannot be NaN and has proper epsilon-aware comparisons?</p> <ol> <li>Switching on a value of type <code>All/Any</code>?</li> </ol>"},{"location":"writeups/0003-multi-types/#pending-questions","title":"Pending questions","text":""},{"location":"writeups/0003-multi-types/#nested-pattern-syntax","title":"Nested pattern syntax","text":"<p>How to handle it? This is a fantastic feature, and we want it.</p>"},{"location":"writeups/0003-multi-types/#compilationdesugaring","title":"Compilation/Desugaring","text":"<p>Sum types can be seen as tagged unions for the most part. A \"tag\", often a byte or small integer value, indicates the variant we are dealing with, and enough memory is allocated to hold an instance of one of the types constituting the sum type.</p> <p>Let's look at the following <code>jinko</code> sum type:</p> <pre><code>type Point(x: int, y: int);\ntype Point3D(x: int, y: int, z: int);\n\ntype Both = Point | Point3D;\n</code></pre> <p>The <code>Both</code> sumtype could be \"compiled\" to something like this in a C-like language:</p> <pre><code>struct Point {\n    int x;\n    int y;\n};\n\nstruct Point3D {\n    int x;\n    int y;\n    int z;\n};\n\nenum Both_tag {\n    BOTH_POINT,\n    BOTH_POINT3D,\n};\n\nunion Both_data, {\n    Point,\n    Point3D,\n};\n\nstruct Both {\n    Both_tag tag;\n    Both_data data;\n};\n</code></pre> <p>We can perform this desugaring directly in <code>jinko</code> code. Let's look at the colors example again.</p> <pre><code>where (color_type_mark, color_value) = (1, Green(is_light: true));\n\n// then, when matching on `color`\nswitch color {\n    _: Red -&gt; {},\n    _: Blue -&gt; {},\n    _: Green -&gt; {},\n}\n\n// could get compiled/lowered to\nswitch color_type_mark {\n    0: Red -&gt; { /* we use color_value */ },\n    1: Blue -&gt; { /* we use color_value */ },\n    2: Green -&gt; { /* we use color_value */ },\n}\n</code></pre> <p>Likewise for anonymous multi-types:</p> <pre><code>func takes_red_or_blue(color: Red | Blue, some_arg: int) {\n    switch color {\n        /* ... */\n    }\n}\n\n// becomes\nfunc takes_red_or_blue(color_type_mark: int, color_value: Red | Blue, some_arg: int) {\n    switch color_type_mark {\n        /* ... */\n    }\n}\n</code></pre> <p>Primitive sum types such as <code>char</code>, <code>string</code> and <code>int</code> are special in that they contain an extremely high number of variants which are handled internally by the compiler. Having a tag for a jinko <code>int</code> would not make sense, as we would need to keep track of <code>u64::MAX</code> variants for the tag enum, as well as the integer it represents. This would effectively make the representation of a 64 bits integer take at least 128 bits in memory, for no good reason at all. We can instead make a special case for the int type and directly use its value as the tag. We can do a similar optimization for <code>char</code> values, which can be seen as small integer (a unicode codepoint takes 4 bytes at most).</p> <p>There is sadly an even higher number of possibilities for strings, as they can take up to <code>u64::MAX</code> bytes of space on most 64-bits platforms. There are 1,114,112 y possible values for a unicode codepoint, so there are literally billions of possible strings - which all need to be contained in the <code>string</code> sum type! This is not representable using a regular C enum, or any usual tag of some sort. Instead, we can simply compare the hashes of strings, which ends up being a \"simple\" integer comparison. We will obviously need to think about collisions, but this is a much more manageable problem.</p>"},{"location":"writeups/0004-error-handling-inside-the-interpreter/","title":"WU0004: Error handling inside jinko's interpreter","text":"<p>Since we are designing a programming language, we must take particular attention in reporting the errors that users are encountering. This means delivering clear and beautiful error messages, which is not the point of this write-up, as well as handling their emission properly. Most errors are not fatal to the programmer: We do not want them to stop the flow of typechecking completely and stop the interpreter. Instead, we want to skip over the offending instruction and check the next one. This allows for emitting multiple errors per interpreter invocation, making for a better development experience.</p> <p>However, the Rust way of handling errors is usually to stop the flow of execution if an error arises, propagating it back to the caller using the <code>?</code> operator. Obviously, this cannot work really well with emitting multiple errors: As soon as one is detected, it will be propagated all the way up to the caller, eventually short-circuiting the <code>main</code> function.</p> <p>To avoid this, we currently store errors inside the various <code>Contexts</code> in the form of an <code>ErrorHandler</code>, which is basically a glorified <code>Vec&lt;jinko::Error&gt;</code> type. <code>jinko::Error</code>s are built using a builder pattern, and then stored in the context's error handler. This causes a lot of code to look like the following:</p> <pre><code>if something_bad() {\n    ctx.error(Error::new(ErrKind::TypeChecker)\n            .with_msg(\"typechecking error!\")\n            .with_loc(self.location())\n            .with_hint(Error::hint()\n                    .with_loc(dec.location())\n                    .with_msg(\"something helpful\")));\n    return;\n    // return nothing, since the function does not return a Result: Errors are\n    // kept in the context\n}\n</code></pre> <p>This produces a lot of noise, and makes for nasty code sprinkled in a lot of places in the interpreter.</p> <p>I believe we should be able to clean that up by categorizing jinko nodes as either \"Aggregation sites\" or \"Emission sites\". Ideally, individual instructions can simply return an error: If they are invalid, there's a good chance that they do not want to keep typechecking and instead want to return early.</p> <p>Let's take the following jinko instruction</p> <pre><code>func add(lhs: int, rhs: int) -&gt; int { lhs + rhs }\n\na = 15.add(14).add(\"5\").add(27)\n//             ^ type error\n</code></pre> <p>In the above example, there's a type error: We're trying to give a string to a function that only takes two integers as arguments. Why should we go further down the line and try to type-check the third call to add? Since the second one is inerently incorrect, there is absolutely nothing to be gained from analyzing the third one. The user might have tried to give an integer instead, and will change <code>\"5\"</code> to <code>5</code>, or they might have wanted to instead call an entirely different function. Hell, maybe they forgot a call to <code>parse[int]()</code> in the middle. That's a lot of possibilities, which we cannot reasonnably account for. Instead, the second method call in there should return an error, which will be propagated by the first method call back to the assignment expression, which should then propagate it as well.</p> <p>Likewise, if we turned the above assignment in an arithmetic operation like so</p> <pre><code>a = 15.add(14).add(\"5\").add(27) * 'k'\n</code></pre> <p>There'd be no point in typechecking that the operation can actually happen. The left hand side of the operator is in an error state, so there is absolutely no way that this code will ever be valid.</p> <p>We will thus refer to the assignment expression, the method call or the binary operation as an Emission Sites. When going through the various static analysis passes, they cannot accumulate errors: They should just propagate them when they happen. Binary operations are a bit special in that they contain two expressions to typecheck, so we might as well go and type check the right hand of the operation for more feedback to the user.</p> <p>This is opposed to Aggregation Sites, such as blocks of code: In a block, multiple separate instructions need to be checked for errors. This causes the user to want multiple errors to be reported:</p> <pre><code>{\n  i1 = 15.add('5');\n  i2 = println(not_a_string);\n  i3 = add(invalid, amount, of_args);\n}\n</code></pre> <p>These 3 instructions have completely separate error messages, which the user would want to be reported all at once. <code>i1</code> should emit an error regarding the type of the argument given to <code>add()</code>, just like <code>i2</code> for a different function and different type. Finally, <code>i3</code> should error out because of the invalid amount of arguments given to the <code>add()</code> function.</p> <p>A block is thus an aggregation site. Upon encountering an error when checking one of its instruction, it should store it, but still check the following instruction it contains before returning in an error state.</p> <p>Since blocks are the base upon which the entirety of jinko is built (they are present in function definitions, loops, if-else blocks...), aggregating errors only in a few places should easily offer a lot of useful feedback to the user while limiting noise in the interpreter's code.</p>"},{"location":"writeups/0007-partial-application-op/","title":"WU0007: Partial Application operator","text":""},{"location":"writeups/0007-partial-application-op/#concept","title":"Concept","text":"<p>It'd be nice for <code>jinko</code> to have an operator specific to the partial application of a function. Let's look at a few examples</p>"},{"location":"writeups/0007-partial-application-op/#why-not-reuse-the-call-operator","title":"Why not reuse the call operator?","text":"<p>Reusing the call operator (<code>f(arg1, arg2)</code>) causes more issues than it solves in my opinion. It murks up the reading of code and makes reasoning about <code>jinko</code> semantics harder. Furthermore, typechecking errors now become confusing, and often, not errors on the call site!</p> <p>Let's take the following example:</p> <pre><code>// TODO: Should be named `add3` really, but isn't...\n// I hope this does not confuse users!\nfunc add(x: int, y: int, z: int) -&gt; int { x + y + z }\n\nwhere x = add(1, 2);\n\nprintln(\"{x}\")\n</code></pre> <p>would produce something similar to the following output:</p> <pre><code>error: source.jk:5:11: cannot format expression of type `func(int) -&gt; int`\n\n  5 | println(\"{x}\")\n    |           ^\n\nhint: no specialization exists for function `fmt` for type `func(int) -&gt; int`\n\n-&gt; stdlib/fmt.jk:\n\n 15 | func fmt[T](value: T) -&gt; string; /* builtin */\n\nhint: consider specializing the function\n\n  5 | func fmt[T: func(int) -&gt; int](value: func(int) -&gt; int) -&gt; string { /* TODO */ }\n</code></pre> <p>As a side note, we could also consider using a similar syntax for generic specialization.</p>"},{"location":"writeups/0007-partial-application-op/#design-considerations","title":"Design considerations","text":""},{"location":"writeups/0007-partial-application-op/#delimiting-partial-arguments","title":"Delimiting partial arguments?","text":""},{"location":"writeups/0007-partial-application-op/#application-of-multiple-arguments-at-once","title":"Application of multiple arguments at once","text":""},{"location":"writeups/0007-partial-application-op/#chaining-applications","title":"Chaining applications","text":""},{"location":"writeups/0007-partial-application-op/#alternatives","title":"Alternatives","text":"<p>Let's keep going with our weirdly named <code>add</code> function.</p> <pre><code>func add(x: int, y: int, z: int) -&gt; int { x + y + x }\n</code></pre>"},{"location":"writeups/0007-partial-application-op/#arg0-arg1-arg2-syntax","title":"<code>| arg0, arg1, arg2... |</code> syntax","text":"<pre><code>where add1 = add |1|;\nwhere res = add(2, 3); // typeck error\nwhere res = add1(2);   // typeck error\n\nwhere res = add1(2, 3); // 1 + 2 + 3, fully applied\n\nwhere add1_2 = add |1, 2|;\nwhere res = add1_2 |3|; // same result, partial application but \"complete\"\n</code></pre>"},{"location":"writeups/0007-partial-application-op/#-arg0-arg1-arg2-syntax","title":"<code>&lt;- (arg0, arg1, arg2...)</code> syntax","text":"<pre><code>where add1 = add &lt;- 1;\nwhere add1_2 = add &lt;- (1, 2); // how to work with tuples?\nwhere add1_2 = add1 &lt;- 2;\n</code></pre>"},{"location":"writeups/0007-partial-application-op/#-arg0-arg1-arg2-syntax_1","title":"<code>&lt;- arg0 &lt;- arg1 &lt;- arg2</code> syntax","text":"<pre><code>where add1 = add &lt;- 1;\nwhere add1_2 = add &lt;- 1 &lt;- 2; // no problem with tuple arguments here\nwhere add1_2 = add1 &lt;- 2;\n</code></pre>"},{"location":"writeups/0007-partial-application-op/#curry-function","title":"<code>curry</code> function?","text":"<p>One could think about having a <code>curry</code> function turning a given function into its partial application</p> <pre><code>// simple case\nfunc curry[T, Z](f: func(T) -&gt; Z) -&gt; func(T) -&gt; Z {\n    |t| f(t)\n}\n\n// two arguments\nfunc curry[T, U, Z](f: func(T, U) -&gt; Z) -&gt; func(T) -&gt; func(U) -&gt; Z {\n    |u| curry(|t| f(t))(u) // uuuuh, that's not valid\n    // how?\n}\n</code></pre> <p>Or have <code>curry</code> as an interpreter builtin? But then it contradicts with the goal of having the interpreter be as small and simple as possible.</p>"},{"location":"writeups/0008-specialization-partial-generics/","title":"WU0008: Specialization, generic application, partial generic application","text":"<p>Let's consider <code>jinko</code>'s memory release mechanism. If the goal is to make copies explicit and moves implicit, one can explicitly ask for a value to be released (and for its memory to be released by the garbage collector) using a simple moving function such as this one;</p> <pre><code>type MegaBigDynamicStruct(a: Vector[Vector[string]] /* wahou! */)\n\nfunc consume(value: MegaBigDynamicStruct) {}\n\nwhere mbds = MegaBigDynamicStruct(a: Vector::new().append(Vector::new().append(\"so dynamic!\"))));\n\nmbds.consume();\n\n// error: use of moved value mbds\nwhere first_string = mbds.a.at(0).at(0);\n</code></pre> <p>We can generalize this mechanism and offer a generic <code>consume</code> function. Since the garbage collector is not guaranteed to run immediately, it's more like you're marking a value for release rather than releasing it. Let's call this function <code>rot</code>, as you're indicating that you're leaving this value to decay and won't be using it anymore.</p> <pre><code>func rot[T](value: T) {}\n</code></pre> <p>...and that's it! We now have a generic function which takes care of indicating to the GC that this value's memory can be reclaimed. We can imagine something like this for <code>jinko</code>:</p> <pre><code>func foo() -&gt; Baz {\n    where a = bar();\n    where b = baz();\n\n    print(\"{a}\");\n\n    b\n}\n</code></pre> <p>One pass the interpreter should have should be to insert calls to <code>rot</code> when possible, in order to reclaim memory. Because in this function <code>foo</code>, <code>a</code> goes out of scope at the end and is not used or returned afterwards like <code>b</code>, we can imagine the following code after said \"rot-pass\", after the last uses of <code>a</code>.</p> <pre><code>func foo() -&gt; Baz {\n    where a = bar();\n    where b = baz();\n\n    print(\"{a}\");\n\n    a.rot();\n    b\n}\n</code></pre> <p>Now, this is all good and dandy, but we can extend this <code>rot</code> mechanism to incur interesting behavior on memory release. For example, a type which takes care of managing an operating system resource, like a file descriptor or dynamic memory.</p> <pre><code>ext func open(path: string, flags: int);\next func read(path: string, flags: int);\n\ntype Error(cause: string);\ntype File(path: string, fd: Maybe[int] = Nothing);\n\nfunc open(f: File) -&gt; Result[File, Error] {\n    switch f.fd {\n        fd: int =&gt; Error(cause: \"file {f.path} is already opened\"),\n        _: Nothing =&gt; {\n            where new_fd = open(f.path, 0);\n            if new_fd == -1 {\n                Error(cause: \"couldn't open file\")\n            } else {\n                File(path: fd.path, fd: new_fd)\n            }\n        }\n    }\n}\n\nfunc read(f: File) -&gt; Result[string, Error] {\n    switch f.fd {\n        fd: int =&gt; {\n            where mut buf = \"\";\n            where ret_val = read(fd, buf.ref_mut(), 1)\n\n            buf\n        }\n        _: Nothing =&gt; f.open().try().read(),\n    }\n}\n\nfunc foo() {\n    where test_file = File(\"test.jk\");\n\n    // here, the interpreter will insert a call to test_file.rot()\n}\n</code></pre> <p>when <code>test_file</code> goes out of scope here, it would be nice for the underlying file descriptor to get closed. This way, we can return the resource to the OS and avoid leaking resources. One way to do so would be to specialize the behavior of <code>rot</code> for <code>File</code> instances, so that it performs a call to <code>close</code>. Let's explore the various syntaxes to achieve this.</p> <pre><code>ext func close(fd: int);\n\nfunc close(f: File) {\n    switch f.fd {\n        fd: int =&gt; close(fd),\n        _ =&gt; {}\n    }\n}\n\n// specialize the rot function for `File`\nfunc rot[???](f: File) {\n    f.close()\n}\n</code></pre> <p>How would the syntax for specifying the generic type <code>T</code> to be <code>File</code> look like?</p> <p>One proposal is as follows <pre><code>func rot[T: File](f: File) {\n    f.close()\n}\n</code></pre></p> <p>This syntax is nice, but does not really allow partial specialization. We could want something like this <code>rot</code> function for vectors or tuples <pre><code>func rot[T: Vector[T]](v: Vector[T]) {\n    for value in v {\n        value.rot()\n    }  \n}\n</code></pre></p> <p>Having an implicit rule for reusing the same generics does not work really well and could get confusing <pre><code>// what is the difference between\nfunc rot[T: Vector[T]](v: Vector[T]);\n// and\nfunc rot[T: Vector[int]](v: Vector[int]);\n// and\nfunc rot[T: Vector[undeclared_type]](v: Vector[undeclared_type]);\n// which one should error out?\n</code></pre></p> <p>Where is the type <code>T</code> used within <code>Vector[T]</code> defined? Is that a type error because <code>Vector[T]</code> refers to a type <code>T</code> which is undefined? Should the syntax be something like this to explicitly declare the second generic? <pre><code>func rot[U][T = Vector[U]](v: Vector[U]); // ?\nfunc rot[T = Vector[U]](v: Vector[U])[U]; // ?\n</code></pre></p> <p>This is basically a partial application of generics. If we solve that syntax issue, we can probably reuse the same syntax for partial function application.</p> <p>The philosophy of generics is that they are usually declared before being used, for example in the case of the generic <code>rot</code> or <code>id</code>.</p> <pre><code>// declared here...\n//       |\n//       |   and used here\n//       |        |     |\n//       v        v     v\nfunc id[T](value: T) -&gt; T {\n    value\n}\n</code></pre> <p>For application however, the specialized type comes after the function or type being used:</p> <pre><code>type Generic[T](value: T);\n\n//      generic applied here\n//                vvv\nwhere g = Generic[int](15);\n</code></pre> <p>so one could think of specialization as generic application, but on a function declaration instead of type <pre><code>func rot[T](value: T)[File] {\n    // value is a `File`\n}\n</code></pre></p> <p>but what about the following examples? <pre><code>// is that an error?\nfunc rot[T](value: File)[File] {}\n\n// where is `T` from `Vec[T]` defined?\nfunc rot[T](value: T)[Vector[T]] {}\n// is this better? where is `U` defined?\nfunc rot[T](value: T)[Vector[U]] {}\n// what's the difference with this?\nfunc rot[T](value: T)[Vector[undeclared_type]] {}\nfunc rot[T](value: T)[Vector[int]] {}\n</code></pre></p> <p>Or we could have entirely different partial function specialization syntax, which could mean \"returns a function specializable on a generic <code>U</code>\"</p> <pre><code>func rot[T: Vec[U]](value: Vec[U]): [U] {\n\n}\n\n// gets a bit uglier here...\nfunc id[T: Vector[U]](value: Vector[U]): [U] -&gt; Vector[U] {\n    value\n}\n</code></pre> <p>or even forego the concept entirely, define each function as a generic type (a callable one), and specialize by defining new bindings</p> <pre><code>func rot[T](value: T) {}\n\nwhere rot[f: File] = {\n    f.close()\n}\n</code></pre> <p>or remove the generics entirely, keeping them only in the case of partial specialization?</p> <p><pre><code>func rot[T](value: T) {}\nfunc rot(value: File) { value.close() }\nfunc rot[T](values: Vector[T]) { for value in values { value.rot() } }\n</code></pre> and have error about \"useless\" specialization? As in, show as duplicate functions? <pre><code>// function already declared here - might be a useless case of specialization?\nfunc rot[U](value: U) {}\n// consider restricting the type `U` further for partial specialization\n// func rot[U](value: ...[U]) {}\n</code></pre></p> <p>which is probably the better solution :)</p> <p>Alternatively, we can also keep generics and add new generics to partially specialized functions:</p> <pre><code>func rot[T](value: T) {}\nfunc rot[T: File](value: File) { value.close() }\nfunc rot[I, T: Vector[I]](value: Vector[I]) { for value in values { value.rot() } }\n</code></pre> <p>Let's take a look at a few examples where partial generic application and specialization become useful:</p> <pre><code>// declaration without a body - there's no \"generic\" way to format something and it should be an error\nfunc format[T](value: T) -&gt; string;\n\n// specialization for the primitive types\nfunc format[T: int](value: int) -&gt; string {\n    format_int(value)\n}\n\nfunc format[T: bool](value: bool) -&gt; string {\n    switch value {\n        true =&gt; \"true\",\n        false =&gt; \"false\",\n    }\n}\n\nfunc format[T: char](value: char) -&gt; string {\n    \"\".concat(value)\n}\n\nfunc format[T: string](value: string) -&gt; string {\n    value\n}\n</code></pre> <p>If we omit the binding syntax (<code>T: whatever</code>), the one thing sticking out to me is that the specialized versions of <code>format</code> look just like regular functions. There is no indication (syntactically) that they are specialized functions. So for example why would this error out</p> <pre><code>func not_spec(a: int) -&gt; int { a }\nfunc not_spec(a: string) -&gt; char { a.at(0) }\n</code></pre> <p>but not <pre><code>func spec[T, U](a: T) -&gt; U;\nfunc spec(a: int) -&gt; int { a }\nfunc spec(a: string) -&gt; char { a.at(0) }\n</code></pre></p> <p>This creates confusing errors for users and isn't a very good show of the language. We could make this good only by having extensive error messages with extremely good examples.</p> <p>Or should we introduce a new function keyword to separate the original function and the specialization?</p> <pre><code>func format[T](value: T) -&gt; string;\nspec format(s: string) -&gt; string { value }\n\nfunc map[T, U](value: T, f: func(T) -&gt; U) -&gt; U {\n    f(value)\n}\nspec map[T, U](value: Maybe[T], f: func(T) -&gt; U) -&gt; Maybe[U] {\n    switch value {\n        contained: T =&gt; f(contained)\n        Nothing =&gt; Nothing\n    }\n}\nspec map[T, U](values: Vector[T], f: func(T) -&gt; U) -&gt; Vector[U] {\n    values.fold(Vector::new(), |vec, value| vec.append(value.map(f)))\n}\n\nfunc fold[In, Out, Elt](\n    values: In,\n    init: Out,\n    folder: func(Out, Elt) -&gt; Out\n) -&gt; Out {\n    where mut output = init;\n    for elt in values {\n        output = folder(output, elt)\n    }\n\n    output\n}\n</code></pre> <p>How to prevent overzealous specialization? For example, specializing <code>map</code> on <code>int</code> and <code>char</code> would not be great. Could it affect users of a library? Should we really disallow it?</p> <pre><code>func format[T](value: T) -&gt; string;\nfunc format[T: string](value: string) -&gt; string { value }\nfunc format[T: int](value: int) -&gt; int { format_int(value) }\nfunc format[T: bool](value: bool) -&gt; int {\n    switch value {\n        true =&gt; \"true\",\n        false =&gt; \"false\",\n    }\n}\n\nfunc map[T, U](value: T, f: func(T) -&gt; U) -&gt; U {\n    f(value)\n}\n\n// isn't this a bit confusing...\nfunc map[I, O, T: Maybe[I], U: Maybe[O]](value: Maybe[I], f: func(I) -&gt; O) -&gt; Maybe[O] {\n    switch value {\n        input: I =&gt; f(input),\n        Nothing =&gt; Nothing,\n    }\n}\n\n// should we go for this instead? yes\nfunc map[I, O][T: Maybe[I], U: Maybe[O]](value: Maybe[I], f: func(I) -&gt; O) -&gt; Maybe[O] { /* ... */ }\nfunc map[I, O](T: Vector[I], U: Vector[O])(\n    values: Vector[I],\n    f: func(I) -&gt; O\n) -&gt; Vector[O] {\n    values.fold(Vector, (vec, elt) -&gt; vec.push(f(elt)))\n}\n\nfunc fold[In, Out, Elt](\n    values: In,\n    init: Out,\n    folder: func(Out, Elt) -&gt; Out,\n) -&gt; Out {\n    where mut output = init;\n    values.iter().for_each(elt -&gt; { output = folder(output, elt) });\n\n    output\n}\n</code></pre>"},{"location":"writeups/0008-specialization-partial-generics/#specializing-functions-only-in-the-current-context","title":"Specializing functions only in the current context","text":"<p>Specialization should only be possible for functions which live in the current namespace/are refered to by their full names. This will avoid a lot of complications with name conflicts, and user defined methods with similar names as library/core ones.</p> <p>Let's take the example of the <code>fmt</code> function, defined in <code>core</code> as follows:</p> <pre><code>func fmt[T](value: T) -&gt; string { /* ... */ }\n</code></pre> <p>Now let's specialize it for our custom type <code>Foo</code>:</p> <pre><code>type Foo;\n\nfunc fmt[T: Foo](f: Foo) -&gt; string { \"Foo\" }\n</code></pre> <p>This should error out, because we are specializing a function whose generic definition does not exist - the generic <code>fmt</code> is not present in the current namespace/definition pool.</p> <p>We can circumvent that by using its full name, or importing <code>fmt</code> into the definition pool:</p> <pre><code>type Foo;\n\nfunc core.fmt[T: Foo](f: Foo) -&gt; string { \"Foo\" }\n\n// or\n\nwhere fmt = core.fmt;\n\ntype Foo;\n\nfunc fmt[T: Foo](f: Foo) -&gt; string { \"Foo\" }\n</code></pre> <p>NOTE: How to output that error? Super confusing if the user just expects <code>fmt</code> to exist to see something like <code>fmt does not exist</code>.</p>"},{"location":"writeups/0008-specialization-partial-generics/#specialization-as-pattern-matching-extension","title":"Specialization as pattern matching extension?","text":"<p>Specialization can be thought of as adding a new case to a generic pattern, e.g.:</p> <pre><code>func fmt[T](x: T) -&gt; string {\n    jinko.error(\"unimplemented function `fmt` for type `{any_type}`\")\n}\n</code></pre> <p>is almost the same as:</p> <pre><code>where fmt = x -&gt; switch x {\n    any_type: _ -&gt; jinko.error(\"unimplemented function `fmt` for type `{any_type}`\"),\n}\n</code></pre> <p>So if we had a syntax for \"extending\" that pattern with new cases/match arms, then it could make sense:</p> <pre><code>// add an implementation of `fmt` for strings\nfmt += s: string -&gt; s;\n\n// for ints and chars\nfmt += i: int -&gt; core.int.int_to_str(i);\nfmt += c: char -&gt; core.string.string_from_char(c);\n\n// for a custom type\nfmt += f: Foo -&gt; \"Foo\";\n</code></pre> <p>But how to have a syntax that makes sense here?</p> <pre><code>func fmt[T](value: T) -&gt; string {\n    jinko.error(\"unimplemented function `fmt` for type `{any_type}`\")\n}\n\nfmt :: i: int -&gt; core.int.int_to_str(i);\nfmt :: s: string -&gt; s;\nfmt :: Foo -&gt; \"Foo\";\n</code></pre>"},{"location":"writeups/0009-closures/","title":"WU0009: Closures","text":""},{"location":"writeups/0009-closures/#syntax","title":"Syntax","text":"<pre><code>// look at previous writeup regarding switches?\npattern := identifier | '(' pattern [ ',' pattern ]* ')'\nclosure := pattern '-&gt;' expr\n</code></pre>"},{"location":"writeups/0009-closures/#tuples-as-argument-lists","title":"Tuples as argument lists","text":""},{"location":"writeups/0009-closures/#how-to-pass-closures-as-arguments","title":"How to pass closures as arguments?","text":""},{"location":"writeups/0009-closures/#how-should-function-arguments-look-like","title":"How should function arguments look like?","text":"<pre><code>func map[T, U](value: Maybe[T], f: Func[(T), U]) -&gt; Maybe[U] {\n    switch value {\n        Nothing =&gt; Nothing,\n        inner: T =&gt; f(inner),\n    }\n}\n</code></pre>"},{"location":"writeups/0009-closures/#how-to-capture-variables","title":"How to capture variables?","text":""},{"location":"writeups/0009-closures/#issues","title":"Issues?","text":""},{"location":"writeups/0009-closures/#design-consideration","title":"design consideration?","text":""},{"location":"writeups/0009-closures/#generalize-to-functions","title":"generalize to functions","text":""},{"location":"writeups/0009-closures/#code-examples","title":"Code examples","text":"<pre><code>where values = [1, 2, 3];\n\nvalues\n  .map(elt -&gt; elt * 2)\n  .zip()\n  .for_each((i, elt) -&gt; println(\"value at {i}: {elt}\"))\n  // or\n  .for_each(tup -&gt; println(\"value at {tup[0]}: {tup[1]}\"))\n</code></pre>"},{"location":"writeups/0009-modules-as-types/","title":"WU0009: Modules as types","text":"<p>This writeup explores the possibility of removing the <code>incl &lt;source&gt;</code> syntax for a more functional approach to \"includes\" or modules as a whole.</p>"},{"location":"writeups/0009-modules-as-types/#existing-solution","title":"Existing solution","text":"<p>The include mechanism currently copies and paste source code in the current scope or in an inner scope. We need to figure out solutions around namespaces and module pathing to be able to use them properly, otherwise they are extremely annoying to use and prone to errors - with similar issues to C, where the lack of namespacing and copy-pasting of code is causing immense pain.</p>"},{"location":"writeups/0009-modules-as-types/#problems","title":"Problems","text":"<ol> <li>Lack of scoping at the time</li> <li>Need special handling</li> <li>Need special handling for inner functions/types</li> <li>Need special path resolution - not present with regular <code>jinko</code> code</li> </ol>"},{"location":"writeups/0009-modules-as-types/#proposed-solution","title":"Proposed solution","text":"<p>Including a module creates a magical type, with fields corresponding to each item present in the module.</p>"},{"location":"writeups/0009-modules-as-types/#bikeshedding","title":"Bikeshedding","text":"<ul> <li> <code>source</code></li> <li> <code>mod</code></li> <li> <code>module</code></li> <li> <code>incl</code></li> <li> <code>with</code></li> <li> <code>import</code></li> <li> <code>jk</code></li> </ul>"},{"location":"writeups/0009-modules-as-types/#issues","title":"Issues","text":""},{"location":"writeups/0009-modules-as-types/#how-should-the-importing-machinery-work","title":"How should the \"importing\" machinery work?","text":"<p>Let's imagine the bikeshedding discussion is over and we have settled on <code>source</code> as the name of the function responsible for importing a module into the current scope. The original plan was for the <code>source</code> function to have the following signature:</p> <pre><code>func source(path: string) -&gt; type;\n</code></pre> <p>This function would create a new, anonymous <code>type</code> and return it - it could then be aliased like so:</p> <pre><code>type foo = source(\"foo\");\n</code></pre> <p>The issue with this is that we do not only want a type, but also an instance of that type: if the module foo defines a function <code>bar</code>, we want <code>foo.bar</code> to point to this specific function, not otherwise. There are multiple solutions to this:</p> <ol> <li>Keep <code>source</code> as a function returning a <code>type</code></li> </ol> <pre><code>func source(path: string) -&gt; type;\n</code></pre> <ul> <li>Instantiate the type upon receptioning it</li> <li>The default parameters for each of the fields contain the proper module values, functions and types</li> </ul> <pre><code>type foo = source(\"foo\");\nwhere foo = foo(); // instantiation \n\n// shorthand\nwhere foo = source(\"foo\")();\n</code></pre> <p>This opens up some possibilities such as specifying a module's function without changing the module or the code refering to it, as long as they are the exact same types? Is that something we want?</p> <pre><code>// foo.jk\nfunc bar() -&gt; int { 14 }\n\n// main.jk\nfunc my_bar() -&gt; int { 16 }\n\nwhere foo = source(\"foo\")(\n    bar: my_bar\n);\n\nfoo.bar() // returns 16\n</code></pre> <p>However, the syntax is unwieldy - should we offer a shorthand so that <code>TypeName;</code> and <code>TypeName();</code> are similar in the case where <code>TypeName</code> contains default values for all of its fields?</p> <p>This would allow the following:</p> <pre><code>where foo_base = source(\"foo\");\nwhere foo_overriden = source(\"foo\")(\n    bar: my_bar,\n);\n</code></pre> <ol> <li>Have <code>source</code> be generic and return an instance of its type parameter</li> </ol> <pre><code>func source[T](path: string) -&gt; T;\n</code></pre> <ul> <li>The magical type generated is now fully opaque and cannot be aliased, or not trivially at least</li> <li>No module overriding (but do we want this in the first place)</li> <li>Simpler syntax</li> <li> <p>Issues with external users specializing the <code>source</code> function? </p> </li> <li> <p>Have <code>source</code> be a type, which offers specializations for each module</p> </li> </ul> <pre><code>type source[T];\n\ntype source[T: \"foo\"](bar: func() -&gt; int); // magic generated by the compiler\n</code></pre> <ul> <li>Same issue as 1</li> <li>Also requires the shorthand initialization for record types with defaults everywhere to be wieldy.</li> </ul> <p>Solution 1 with the type initialization shorthand has the cleanest syntax while offering module item overriding, which might be something interesting. If we do not want that, then solution 1 remains the clearest IMO.</p> <p>Since we have UFCS, it also means that this syntax will be valid:</p> <pre><code>type foo = \"foo\".source();\n</code></pre> <p>Having the <code>source</code> mechanism be a function also allows extra optional parameters, such as the path of the file to source:</p> <p>In Rust:</p> <pre><code>#[path = \"utils/bar.jk\"]\nmod foo;\n</code></pre> <p>becomes</p> <pre><code>type foo = source(\"foo\", path = \"utils/bar.jk\");\n</code></pre>"},{"location":"writeups/0009-modules-as-types/#requires-first-class-types","title":"Requires first class types","text":"<p>Let's say that we want to source the following <code>utils</code> module:</p> <pre><code>// foo.jk\n\ntype Left[L](inner: L);\ntype Right[R](inner: R);\ntype Either[L, R] = Left[L] | Right[R];\n\nfunc is_left[L, R](value: Either[L, R]) -&gt; bool {\n    switch value {\n        _: Left -&gt; true,\n        _ -&gt; false,\n    }\n}\n</code></pre> <p>Accessing the <code>is_left</code> function with the proposed solution is quite easy - our magic type will have an <code>is_left</code> member of type <code>func[L, R](Either[L, R]) -&gt; bool</code>; But how do we actually access the <code>Either</code> type? <code>utils.Either</code> would be nice, but it does mean that the generated <code>utils</code> type needs a field named <code>Either</code> which would be of type... <code>type</code>?</p>"},{"location":"writeups/0009-modules-as-types/#first-solution-type-specialization-crimes","title":"First solution: Type specialization crimes","text":"<ol> <li>Add type specialization</li> <li>Generate a basic <code>util[T = ()]</code>  type which contains all of the members of our module except for the types.</li> <li>Specialize <code>util</code> as each type within the module, so something like this</li> </ol> <pre><code>where utils = source(\"utils\");\n\n// becomes\n\ntype utils[T = ()](\n    is_left: func[L, R](Either[L, R]) -&gt; bool,\n)\n\ntype utils[L, T: Left](inner: L);\ntype utils[R, T: Right](inner: R);\ntype utils[L, R, T: Either] = utils[Left][L] | utils[Right][R];\n</code></pre> <p>which we can use like so:</p> <pre><code>// main.jk\n\nwhere value: utils[Either] = utils[Left](inner: 156);\n\nutils.is_left(value);\n</code></pre> <ul> <li>Problems with this solution<ul> <li>Different syntax from module functions and module variables</li> <li>Unwieldy</li> <li>Ugly as sin</li> <li>Requires type specialization - do we want that?</li> </ul> </li> </ul> <p>Really not a fan of this solution</p>"},{"location":"writeups/0009-modules-as-types/#second-solution-first-class-types","title":"Second solution: First class types","text":"<pre><code>where utils = source(\"utils\");\n\n// becomes\n\ntype utils(\n    Left: type,\n    Right: type,\n    Either: type,\n    is_left: func[L, R](utils.Either[L, R]) -&gt; bool,\n);\n</code></pre> <p>which we can use like so:</p> <pre><code>// main.jk\n\nwhere value: utils.Either = utils.Left(inner: 156);\n\nutils.is_left(value);\n</code></pre> <ul> <li>Problems with this solution<ul> <li>Requires self referential types (<code>utils.is_left</code> is of type <code>func[L, R](utils.Either[L, R]) -&gt; bool</code>)</li> <li>Requires first class type support</li> <li>How to instantiate a <code>utils.Either</code> when we only know it's a type and not more?<ul> <li>Runtime type information?</li> <li>How to compile that?</li> </ul> </li> </ul> </li> </ul>"},{"location":"writeups/0009-modules-as-types/#side-notes","title":"Side notes","text":""},{"location":"writeups/0009-modules-as-types/#type-type-information","title":"<code>type</code> type information","text":"<p>Sidenote: <code>type</code> types should probably have way more information, similarly to <code>func</code> types:</p> <pre><code>type utils(\n    Left: type[L](L),\n    Right: type[R](R),\n    Either: type[L, R](utils.Left[L] | utils.Right[R]),\n    is_left: func[L, R](utils.Either[L, R]) -&gt; bool,\n);\n</code></pre>"},{"location":"writeups/0009-modules-as-types/#module-overriding","title":"Module overriding","text":"<p>How to propagate the changes to the rest of the instance if we do override a type's default parameter? Taking the above example, what should happen in this case?</p> <pre><code>type MyEither[L, R](inner: L | R);\n\nwhere utils = source(\"utils\")(\n    Either: MyEither,\n);\n</code></pre> <p>This won't work, because the <code>Either</code> field is of type <code>type[L, R](utils.Left[L] | utils.Right[R])</code> - so since <code>MyEither</code> does not have the proper field types, it fails to typecheck. So it'll work only if we redefine <code>Left</code> and <code>Right</code> as well.</p> <pre><code>type MyL[T](T);\ntype MyR[T](T);\ntype MyEither[L, R](inner: MyL[L] | MyR[R]);\n\nwhere utils = source(\"utils\")(\n    Left: MyL,\n    Right: MyR,\n    Either: MyEither,\n);\n</code></pre> <p>I'm thinking that this mostly would be useful for functions, or for some niche optimizations?</p> <ol> <li>Functions</li> </ol> <p>Let's say you'd like to add logging to the standard's library hashmap because you want to understand exactly how your values are being inserted in your map</p> <pre><code>where map = source(\"map\")(\n    insert: insert_with_log,\n);\n\nfunc insert_with_log[K, V](map: HashMap[K, V], key: K, value: V) -&gt; HashMap[K, V] {\n    // memoized so it's not too costly\n    where original_map = source(\"map\");\n\n    println(\"inserting key {key} with value {value} into the map!\");\n\n    original_map.insert(map, key, value)\n}\n\nwhere map = HashMap;\nwhere map = map.insert(\"key\", \"value\"); // calls `insert_with_log`\n</code></pre> <ol> <li>Niche optimizations</li> </ol> <p>If you know that you will be using a small hashmap for example, you might want to override the map's module <code>Vector</code> type to use a <code>SmallVec</code> kind of implementation</p> <pre><code>type SmolVector = source(\"small_vec\").SmallVec;\n\nwhere map = source(\"map\")(\n    Vector: SmolVector,\n);\n</code></pre> <p>This syntax needs a loooot of bikeshedding however. This is not pretty.</p>"},{"location":"writeups/0009-modules-as-types/#ufcs-method-resolution","title":"UFCS method resolution","text":"<p>How to decide what function <code>12.foo()</code> should resolve to if <code>foo</code> was imported from a module?</p> <ol> <li>Enforce function reexporting</li> </ol> <pre><code>where module = source(\"bar\");\nwhere foo = module.foo;\n\n12.foo(); // resolves to foo -&gt; resolves to module.foo\n</code></pre> <ol> <li>Look through the fields of variables in scope for a matching signature?</li> </ol> <pre><code>where module = source(\"bar\");\n\n12.foo(); // resolves to module.foo\n</code></pre> <ul> <li>Isn't that super unexpected as a behavior?</li> </ul> <pre><code>type SomeOtherType(\n    foo: func(int),\n);\n\nfunc my_foo(a: int) {}\n\nwhere some_other_thing = SomeOtherType(foo: my_foo);\nwhere module = source(\"bar\");\n\n12.foo(); // resolves to module.foo OR some_other_thing.foo\n// ambiguity? weird error reporting?\n</code></pre>"},{"location":"writeups/0010-first-class-types/","title":"WU0010: First class types","text":"<p>note: Reified types?</p>"},{"location":"writeups/0011-shell-abstractions/","title":"WU0011: Shell abstraction","text":"<p><code>jinko</code> being a scripting language, interacting with the user's shell is a priority. We need to be able to build solid abstractions over shell commands as well as functionality such as piping, redirection, command chaining, etc, while still being able to inspect a command's output, error output, and exit code.</p> <p>The idea solution would be something centered around types - but how, and which types? How do we define them? How do we compile them?</p>"},{"location":"writeups/0011-shell-abstractions/#ideas","title":"Ideas","text":"<ol> <li>Extensible <code>Shell</code> type</li> </ol>"},{"location":"writeups/0011-shell-abstractions/#extensible-shell-type","title":"Extensible <code>Shell</code> type","text":"<p>By having a base generic <code>Shell</code> type which has a couple methods, such as <code>.arg()</code> and <code>.execute()</code>, we can abstract almost all shell command building functionality before executing said command. It probably needs a couple more methods to enable piping functionality and redirection.</p> <pre><code>// shell.jk\n\ntype Shell[T = void](\n    cmd: string,\n    args: Vector[string] = Vector(), // default argument to an empty vector, so we can just do `Shell(cmd: ...)`\n);\n\ntype Output(exit_code: int, stdout: string, stderr: string);\n\nfunc arg[T](sh: Shell[T], arg: string) -&gt; Shell[T] {\n    Shell(cmd: sh.cmd, args: sh.args.push(arg))    \n}\n\nfunc execute[T](sh: Shell[T]) -&gt; Output {\n    where cmd_string = sh.args.fold(sh.cmd,\n        (cmd_string, arg) -&gt; cmd_string.concat(' ').concat(arg));\n\n    where exit_code = std.os.system(cmd_string);\n\n    // some magic to get stdout and stderr\n\n    Output(exit_code, stdout, stderr)\n}\n\n// specialization for \"cat\"\ntype Shell[T: \"cat\"](\n    // missing some options but w/ever\n    show_numbers: bool = false,\n    show_tabs: bool = false,\n    show_ends: bool = false,\n    args: Vector[string] = Vector(),\n);\n\nfunc show_numbers(sh: Shell[\"cat\"]) -&gt; Shell[\"cat\"] {\n    Shell[\"cat\"](show_numbers: true, ..sh)\n}\nfunc show_tabs(sh: Shell[\"cat\"]) -&gt; Shell[\"cat\"] {\n    Shell[\"cat\"](show_tabs: true, ..sh)\n}\nfunc show_ends(sh: Shell[\"cat\"]) -&gt; Shell[\"cat\"] {\n    Shell[\"cat\"](show_ends: true, ..sh)\n}\n</code></pre> <pre><code>// main.jk\n\ntype shell = source(\"shell\");\ntype Shell = shell.Shell;\ntype Output = shell.Output;\n\nwhere output = Shell[\"cat\"]()\n    .show_numbers()\n    .show_tabs()\n    .arg(\"a_specific_file.txt\")\n    .execute();\n</code></pre>"},{"location":"writeups/0012-default-field-access/","title":"WU0012: Default field accesses","text":""},{"location":"writeups/0012-default-field-access/#reasoning","title":"Reasoning","text":"<p>The <code>source</code> function exposed in WU0009 is more likely to return a new type than an instance of that type, for numerous reasons including module member overriding and simplicity. However, one question remains: how to access the members of a module without first creating an instance of that type?</p>"},{"location":"writeups/0012-default-field-access/#proposal-1","title":"Proposal 1","text":"<p>Introduce a new operator <code>::</code> to access a type's default field value</p> <pre><code>type list = source(\"list\");\n\nwhere l = list.map([1, 2, 3], x -&gt; x * 2);\n</code></pre> <p>In the above example, <code>List</code> is not an instance of the type <code>List</code> - it is the actual List type. You can imagine that it contains the following fields:</p> <pre><code>type list(\n    map: func[T, U](Array[T], func(T) -&gt; U) -&gt; Array[U] = /* default map */\n);\n</code></pre> <p>Hence, accessing the <code>map</code> field requires an instance of type <code>List</code> - so we must first create one:</p> <pre><code>type list = source(\"list\");\nwhere list = list;\n\nwhere l = list.map([1, 2, 3], x -&gt; x * 2);\n</code></pre> <p>This is unwieldy, boilerplate-y and not very fun to work with. The syntax from the first code snippet makes a lot more sense, and is a lot more manageable. However, it does not make sense to allow accessing a type's field without an instance of that type, and it could be quite error prone.</p>"},{"location":"writeups/0012-default-field-access/#explanation","title":"Explanation","text":"<p>Adding an <code>::</code> operator to explicitly indicate that we would like to use a type's field's default value (provided it exists) makes intent clearer, while still keeping syntax simple. It also has the advantage of still allowing module member overriding.</p>"},{"location":"writeups/0012-default-field-access/#examples","title":"Examples","text":"<pre><code>type list = source(\"list\");\n\nwhere l = list::map([1, 2, 3], x -&gt; x * 2);\n</code></pre> <pre><code>type foo = source(\"foo\");\n// has module `bar`, which has module `baz`, which has type `Qux`\n\nwhere q = foo::bar::baz::Qux(x: 15, y: 14);\n</code></pre> <pre><code>func foo_pair(p: std::pair::Pair[int, string]) -&gt; int { p.fst }\n</code></pre>"},{"location":"writeups/0012-default-field-access/#issues","title":"Issues","text":"<ol> <li>How to deal with module overriding?</li> </ol> <pre><code>type list = source(\"list\");\nwhere list_custom = List(\n    map: our_map,\n);\n\nlist::map([1, 2, 3], x -&gt; x * 2)\n\n// these call `our_map`\nlist_custom::map([1, 2, 3], x -&gt; x * 2) // works?\nlist_custom.map([1, 2, 3], x -&gt; x * 2) // works for sure, but not consistent?\n\nfunc our_map[T, U](l: Array[T], f: func(T) -&gt; U) -&gt; Array[U] { /* ... */ }\n</code></pre> <p>-&gt; should the operator be a <code>field access or default access operator</code>?</p> <ol> <li>module override instances vs default type accesses</li> <li>syntax complexity</li> <li>\"method\" resolution</li> <li>Multiline chaining allowed?</li> <li>Prefered syntax for modules - lowercaps module names?</li> <li>How does it interact with types in general?</li> <li>Other operators?</li> </ol> <pre><code>type Pair = std::pair::Pair;\ntype Pair = std\\pair\\Pair;\ntype Pair = std@pair@Pair;\ntype Pair = std-&gt;pair-&gt;Pair;\ntype Pair = std&gt;pair&gt;Pair;\ntype Pair = std~pair~Pair;\ntype Pair = std^pair^Pair;\ntype Pair = std!pair!Pair;\ntype Pair = std?pair?Pair;\n</code></pre>"},{"location":"writeups/0012-default-field-access/#proposal-2","title":"Proposal 2","text":"<p>Create a binding of an instance of the generated type in the enclosing scope of the receiver expression calling <code>source</code></p> <pre><code>type list = source(\"list\");\n\n// becomes\n\ntype list(\n    map: func[T, U](Array[T], func(T) -&gt; U) -&gt; Array[U] = /* default map */)\n);\n\n// binding with default initialization for all fields of the type `list`\nwhere list = list();\n</code></pre> <pre><code>func source(path: string) -&gt; type {\n    type new_type = source_inner(path);\n    where receiver = jinko.magic.receiver_expr();\n\n    receiver.scope().insert(\n        jinko.magic.binding(receiver.name(), new_type())\n    );\n\n    new_type\n}\n</code></pre>"},{"location":"writeups/0012-default-field-access/#proposal-3","title":"Proposal 3","text":"<p>Make the <code>.</code> operator access the default value if it is on a type, the field if it is on an instance</p> <pre><code>// list.jk\ntype Array[T] = /* ... */;\nfunc map[T, U](arr: Array[T], f: T -&gt; U) -&gt; Array[U] {\n    /* ... */\n}\n\ntype list = source(\"list\");\nlist.map([1, 2, 3], x -&gt; x * 2);\n\n// calls &lt;list module&gt;.map(Array[1, 2, 3], x -&gt; x * 2)\n\nwhere list = list.from([1, 2, 3]); // -&gt; &lt;list module&gt;.Array\nlist.map(x -&gt; x * 2); // calls into &lt;list module&gt;.map(list, x -&gt; x * 2)\n</code></pre>"},{"location":"writeups/0012-default-field-access/#issues_1","title":"Issues","text":"<ol> <li>Very magic</li> <li>Not great for compilation</li> </ol>"},{"location":"writeups/0013-kind-system/","title":"WU0013: Kind system","text":""},{"location":"writeups/0013-kind-system/#reasoning","title":"Reasoning","text":"<p>First class types are extremely useful, but do not play well with static typing - for example, what is the language supposed to do in cases such as:</p> <pre><code>func make_type(b: bool) -&gt; type {\n  if b {\n    TypeBuilder.new().field(\"name\", string)\n  } else {\n    TypeBUilder.new().field(\"a\", int)\n  }\n}\n\ntype Foo = make_type(get_user_input_as_bool())\n\nfunc say_name[T](value: T) {\n  println(value.name)\n}\n\nFoo(a: 15).say_name()\n</code></pre> <p>If <code>false</code> is given as an argument to <code>make_type</code>, then the generated type will contain a field named \"a\" of type <code>int</code>. Otherwise, it will contain only one field \"name\" of type <code>string</code>. The second type is a valid type to the function <code>say_name</code>, but the first one isn't. Allowing this behavior to error out at runtime rather than during typechecking is closer to dynamic typing, which <code>jinko</code> should not support. Thus, we must find a solution to restrain these \"type generator\" functions to compile time arguments.</p> <p>I see two solutions to this problem:</p> <ol> <li> <p>Restrict arguments and return type of type generators to compile time values</p> </li> <li> <p>Introduce a new <code>kind</code> syntax as a shorthand for a compile time function which returns a new type</p> </li> </ol>"},{"location":"writeups/0013-kind-system/#proposal-1","title":"Proposal 1","text":"<p>We could have a magical <code>CompileTime[T]</code> type which would force its initializers to be compile time constants, e.g. by restricting the creation of a <code>CompileTime[T]</code> if <code>T</code> comes from an <code>Impure[T]</code></p> <p>Bikeshedding:</p> <ul> <li> <code>CompileTime[T]</code></li> <li> <code>Known[T]</code></li> <li> <code>Folded[T]</code></li> <li> <p> <code>Foldable[T]</code> -&gt; sounds like something you could call <code>.fold()</code> on</p> </li> <li> <p>Since we are in an interpreted language, any pure function can be a compile-time argument, correct?</p> </li> <li>We need an <code>Impure</code> type to mark functions which interact with the outside world</li> </ul> <p>The syntax for type generators would then look something like this:</p> <pre><code>func make_type(b: Known[bool]) -&gt; Known[type] {\n  /* ... */\n}\n\nfunc extend(\n  t: Known[type],\n  field_name: Known[string],\n  field_type: Known[type]\n) -&gt; Known[type] {\n  /* ... */\n}\n\ntype Foo = make_type(true);\ntype Bar = extend(Foo, \"another_field\", int);\n</code></pre> <p>The main issue with this is that we would be special casing functions returning <code>type</code>s anyway, so why require the addition of that type? We would need special handling for these anyway.</p>"},{"location":"writeups/0013-kind-system/#proposal-2","title":"Proposal 2","text":"<p>Add the notion of <code>kind</code> and a \"kind system\", which is a shorthand for functions generating new types at compile time.</p> <p>A <code>kind</code> can be though of as a function which takes compile time constants as arguments and returns a new type.</p> <pre><code>kind MakeType[b: bool] {\n  /* ... */\n}\n\nkind Extend[t: type, field_name: string, field_type: type] {\n  /* ... */\n}\n\ntype Foo = MakeType[true];\ntype Bar = Extend[Foo, \"another_field\", int];\n</code></pre> <p>This has the advantage that reusing the generic syntax makes it clear this is compile time only. Furthermore, it does not derive from the notion that <code>jinko</code> should only have three concepts - labels, types and functions. A <code>kind</code> is simply a sort of function which returns a new type.</p>"},{"location":"writeups/0013-kind-system/#examples","title":"Examples","text":"<pre><code>kind Extend[t: type, field_name: string, field_type: type] {\n  where new_type = t.fields().fold(TypeBuilder.new(),\n    (new_type, field) -&gt; new_type.with(field)\n  );\n\n  new_type.with_field(TypeBuilder.Field(field_name, field_type))\n}\n\ntype Point(x: int, y: int);\ntype Point3d = Extend[Point, \"z\", int];\n\nkind Intersection[t: type, u: type] {\n  where all_fields = t.fields().append(u.fields());\n\n  where new_fields = all_fields.filter(|field| t.fields().contains(field) &amp;&amp; u.fields().contains(field));\n\n  TypeBuilder.new().fields(new_fields)\n}\n\ntype Foo(a: int, b: int, c: string, d: int);\ntype Bar(b: string, c: string, d: float);\ntype Baz = Intersection[Foo, Bar]; // (c: string)\n\nkind Source[path: string] { /* ... */ }\n\n// Vectors of ZSTs are a little particular, in that they don't need to contain any allocation or capacity - simply a size.\n// If the size is greater than zero, then they can simply return a copy of the ZST. Otherwise, they return nothing. Each\n// `pop` decrements the size, and each `push` increments the size. This is a massive win for Vecs of marker types. We\n// implement this distinction using a kind.\nkind Vector[t: type] {\n  where common_vec = TypeBuilder.new()\n    .field(\"size\", int)\n    .field(\"inner_get\", func[T](Vector[T], int) -&gt; Maybe[T]);\n\n  switch t {\n    zst: Zst -&gt; common_vec\n      .field(\"data\", zst),\n    other: _ -&gt; common_vec\n      .field(\"data\", RawPointer[other])\n      .field(\"capacity\", int),\n  }\n}\n\nfunc inner_get_zst[T](v: Vector[T], idx: int) -&gt; Maybe[T] {\n  if v.size &gt; 0 {\n    v.data\n  } else {\n    Nothing\n  }\n}\n\nfunc inner_get[T](v: Vector[T], idx: int) -&gt; Maybe[T] {\n  if i &lt; v.size {\n    v.data.offset_at(i * T.size())\n  } else {\n    Nothing\n  }\n}\n\nfunc get[T](v: Vector[T], idx: int) -&gt; Maybe[T] {\n  Vector[T].inner_get(v, idx)\n}\n</code></pre>"},{"location":"writeups/0013-kind-system/#drawbacks","title":"Drawbacks","text":"<ul> <li> How to handle errors? <code>kind</code>s returning an invalid type/error type?</li> <li> What does the type system look like for these?</li> <li> How does it interact with generics?</li> <li> UFCS for kinds? -&gt; No</li> </ul>"},{"location":"writeups/0014-type-system/","title":"WU0014: Type system","text":"<p>This writeup details <code>jinko</code>'s type system, based on a primitive kind system. It does not need a kind system to exist, but the kind system is a way to extend the type system further.</p> <p>Recommended reading: Haskell's kind system - a primer</p>"},{"location":"writeups/0014-type-system/#kinds","title":"Kinds","text":"<p><code>kind</code>s are a way to describe types and type constructors within <code>jinko</code>'s type system. Let's take a few examples to illustrate our problem:</p> <pre><code>type Point(x: int, y: int);\n</code></pre> <p>the type <code>Point</code> is of kind <code>type</code>. It is a fully formed type, which you can instantiate directly - similarly to <code>int</code> or <code>string</code>:</p> <pre><code>where x: int = 15;\nwhere y: string = \"foo\";\nwhere p: Point = Point(x: 1, y: 2);\n</code></pre> <p>In the Haskell world, we would say that <code>Point</code> is of kind <code>*</code>, which we will call <code>type</code> here.</p> <p>On the other hand, let's consider a type with a generic argument: <pre><code>type PairSame[T](fst: T, snd: T);\n</code></pre></p> <p><code>PairSame[T]</code> is not a fully fledged type - you cannot instantiate a variable of type <code>Point[T]</code> - <code>T</code> must be known:</p> <pre><code>where p: PairSame[T] = PairSame[T](fst: ???, snd: ???); // invalid\nwhere p: PairSame[int] = PairSame[int](fst: 14, snd: 15);\nwhere p: PairSame[string] = PairSame[string](fst: \"str\", snd: \"ing\");\n</code></pre> <p>Hence why you could see <code>Point[T]</code> as a \"type constructor\". It takes an extra type <code>T</code> as an argument, and \"creates\" a fully fledged type through monomorphization. You can think of <code>Point[T]</code> as a sort of function which will take a type as its only argument, and return a new type.</p> <p>In Haskell, <code>Point[T]</code> would be of kind <code>* -&gt; *</code>: from a fully fledged type of kind <code>*</code>, create a new fully fledged type of kind <code>*</code>. We will say that <code>Point[T]</code> has kind <code>type -&gt; type</code>.</p> <p>Even more complicated: <code>jinko</code>'s module system creates a new <code>type</code> out of the path of a module, encoded as a string. Out of a <code>string</code>, create a new <code>type</code>. This has kind <code>string -&gt; type</code>. If we imagine a \"thing\" which requires an integer and a type to return a new type, then that \"thing\" would be of kind <code>(int, type) -&gt; type</code>.</p>"},{"location":"writeups/0014-type-system/#creating-types","title":"Creating types","text":"<p>With this knowledge in mind, <code>jinko</code>'s type system can be thought of as an interpreter which only deals with kinds and which has no side-effects. All of the execution and logic happens during type-checking. In that system, a concrete type of kind <code>type</code> can be thought of as a regular immutable variable/binding. A type constructor of kind <code>type -&gt; type</code> can be thought of as a regular function.</p> <p>In the following code examples, comments will be added around the various types to show the kinds we are dealing with:</p> <pre><code>type Foo; // :: type\n\ntype Foo[T]; // :: type -&gt; type\n</code></pre> <p>There are two different types in <code>jinko</code>: sum types and record types. Sum types are made of multiple possible types but instances of a sum type are only ever one type. Record types on the other hand, are a product type: they contain multiple instances of possibly multiple types.</p> <pre><code>type Foo;\ntype Bar(a: int, b: Foo);\n</code></pre> <p>In the above example, <code>Foo</code> is a record type with no data fields. <code>Bar</code> is a record type with two fields: <code>a</code>, of type <code>int</code>, and <code>b</code>, of type <code>Foo</code>.</p> <pre><code>func foo(a: int | bool | char) {}\n</code></pre> <p>Here on the other hand, the argument <code>a</code> is of the sum type <code>int | bool | char</code>. <code>a</code> will be either an integer, a boolean or a character. Let's add the kinds to these two examples:</p> <pre><code>type Foo; // :: type\ntype Bar(\n  a: int, // :: type\n  b: Foo, // :: type\n); // :: type\n\nfunc foo(\n  a: int | bool | char // :: type\n) {}\n</code></pre> <p>We can extract a few things from these examples. The <code>type</code> keyword can be used to create new types, of kind <code>type</code> - new, fully fledged types. We can also use it to create type aliases:</p> <pre><code>type Foo; // :: type\ntype Bar = Foo; // :: type\n</code></pre> <p>This is similar to creating two \"variables\" in a regular piece of code. One is named <code>Foo</code>, and the other, <code>Bar</code>, refers to <code>Foo</code>. <code>Bar</code> is a type alias of <code>Foo</code> - not a new type. Anywhere <code>Foo</code> is used, <code>Bar</code> could be used, and vice-versa.</p> <p>Another concept we introduce in the above example is that function arguments can be typed with values of kind <code>type</code>. It is not possible for a function argument to be of kind <code>type -&gt; type</code>, or other type constructors. This is an important concept, as one could think tihs is not the case with the following example:</p> <pre><code>func foo[T](value: Maybe[T]) {}\n</code></pre> <p>However, this function is only valid when fully monomorphized - meaning that <code>value</code> will only ever accept a type of kind <code>type</code>.</p>"},{"location":"writeups/0014-type-system/#sets","title":"Sets","text":"<p>In <code>jinko</code>, types can all be represented as sets. According to wikipedia, sets are \"the mathematical model for a collection of different things\", so we will call the components of our sets \"things\".</p> <p>Thus, in <code>jinko</code>, a type is a <code>Set</code> of <code>Thing</code>s. The notation we will use in the examples is as follows:</p> <ol> <li>Each <code>Thing</code> will be written as its name: <code>int</code>, <code>Complex</code>, <code>float</code></li> <li>Each type will be represented as the set of its things using curly brackets: <code>{ int, string }</code></li> </ol> <pre><code>where x /* { int } */ = 15;\n\nwhere y: string | int /* { string, int } */ =\n  if condition() { x } else { \"none\" }\n</code></pre> <p>We can add a number of rules around sets and things:</p> <ol> <li>The type of a binding is always a <code>Set</code>, even if it contains only one <code>Thing</code></li> </ol> <pre><code>where x = 196.4; // { float }\n\nfunc foo(\n    a: int,  /* { int } */\n    b: bool, /* { bool } */\n) -&gt; char    /* { char } */ {\n    'a'      /* { char } */\n}            /* { func({int}, {bool}) -&gt; {char} } */\n</code></pre> <ol> <li><code>switch</code> expressions are the only ones allowed to explore the <code>Thing</code>s within a <code>Set</code></li> </ol> <pre><code>where x = int | string | char = '1'; // { int, string, char }\n\nswitch x {\n    i: int -&gt; handle_int(i       /* { int } */),\n    s: string -&gt; handle_string(s /* { string } */),\n    c: char -&gt; handle_char(c     /* { char } */),\n}\n</code></pre>"},{"location":"writeups/0014-type-system/#an-interpreter-of-type-variables","title":"An interpreter of type variables","text":""},{"location":"writeups/0014-type-system/#type-widening","title":"Type widening","text":"<p>Process of replacing the type of a variable with a sum type containing its original type.</p> <p>e.g. for a variable of type <code>A | B | C</code>, assign it the type <code>A | B | C | D | E</code>.</p> <p>In set terms: we are replacing a given set <code>E</code>, by a set <code>F</code> containing all the elements of <code>E</code> and one or more elements.</p> <pre><code>func foo(\n  a: int | string // :: type { int, string }\n) {}\n\nfoo(15); // 15 :: type { int }\nfoo(\"jinko\"); // \"15\" :: type { string }\n</code></pre> <p>Both the expressions above are correct and typecheck properly. In both cases, the value given to <code>foo</code> will see its type \"widened\" to the type of <code>a</code>: <code>int | string</code>. Type widening does not occur if the expression is already of the expected type, etc:</p> <pre><code>where x: int | string = // :: type { int, string }\n    if condition() {\n        15 // :: type { int }\n    } else {\n        \"jinko\" // :: type { string }\n    };\n\nfoo(x); // x :: type { int, string }\n</code></pre> <p>In the last call to <code>foo</code>, no widening needs to happen - both the set of <code>x</code> and the set of <code>a</code> are already equal to one another.</p>"},{"location":"writeups/0014-type-system/#type-narrowing-or-flow-sensitive-typing","title":"Type narrowing, or flow-sensitive typing","text":"<p>Flow-sensitive typing is the process of \"narrowing down\" (as opposed to \"type widening\") the sum type of an expression to one variant of that sum type.</p> <p>e.g. for a variable of type <code>A | B | C | D</code>, allow narrowing it down to a variable of type <code>A</code>, OR one variable of type <code>B</code>, OR one variable of type <code>C | D</code>.</p> <p>Flow-sensitive typing can only happen in switch expressions.</p> <p>This is an important distinction from other languages with flow-sensitive typing. <code>jinko</code> does not allow flow-typing in <code>if-else</code> expressions, and all flow-typing must be exhaustive.</p> <p>Reduce a given set <code>E</code> of <code>n</code> elements to <code>n</code> or less sets containing possibly only one element.</p>"},{"location":"writeups/0014-type-system/#set-expansion","title":"Set expansion","text":""},{"location":"writeups/0014-type-system/#representation-of-type-variables","title":"Representation of type variables","text":"<p>Type variables need to be represented in a way that is simple to understand, and simple to reason about. The easiest way is to represent them as a set of type nodes - basically a set of indexes into the <code>Fir</code>. This works well for simple types, but completely falls apart for our \"magic\" builtin primitive union types: <code>int</code>, <code>char</code> and <code>string</code>. While it is possible to represent them as sets of all possible integer, character and string literals, it does not make sense to do so and will certainly incur a heavy compilation penalty. We can then think about representing our type variables like this:</p> <pre><code>enum Type {\n    /// A primitive union type: int, char or string. The index corresponds to the definition of\n    /// that type in the standard library.\n    PrimitiveUnion(OriginIdx),\n    /// A \"regular\" type. The index corresponds to the definition, and the typeset to the set of \n    /// types represented by that definition.\n    Set(OriginIdx, TypeSet),\n}\n</code></pre> <p>For our subtyping rules, we can simply check if a given typeset is contained in the expected typeset. But this does not work for primitive type unions: We do not know in advance the indexes of all constants used in a program, and cannot easily know if a constant's type index is present in a union's type index: Let's look at this with the following program.</p> <pre><code>type char;\ntype int;\ntype string;\n\nwhere x = 15;\n</code></pre> <p>Since <code>x</code> will be of type <code>15</code>, it's as if we had an extra type declaration in the program:</p> <pre><code>type char;\ntype int;\ntype string;\n\ntype 15;\n\nwhere x = 15;\n</code></pre> <p>Now let's add type variables to all our expressions. Remember that a record type will show up as a typeset of one member, itself.</p> <pre><code>// Type::PrimitiveUnion(1)\ntype char;\n// Type::PrimitiveUnion(2)\ntype int;\n// Type::PrimitiveUnion(3)\ntype string;\n\n// Type::Set(4, { 4 });\ntype 15;\n\n// Type::Set(4, { 4 }) // same type as `type 15`\nwhere x = 15;\n</code></pre> <p>There is absolutely zero link between the type of the constant <code>15</code> and the union type <code>int</code>. Checking if the set of <code>15</code> fits within the set of <code>int</code> does not make sense, since the set of <code>int</code> is empty.</p> <p>There are multiple ways to solve this problem:</p> <ol> <li>When doing typeset comparisons, fetch node information from the <code>Fir</code>. This allows us to look at a node's AST data, and to check if it is an <code>int</code> constant or not - if that is the case, then that node can be widened to a node of type <code>int</code>.</li> <li>When typing constant nodes, add extra information regarding the primitive type they could widen to. Basically storing something like <code>Type::ConstantSet(4, can_widen_to: \"int\")</code> in the above example. This works but is delicate, spaghetti, and causes us to add an extra variant to our enum</li> <li>Collect a list of all the constants in a program in order to actually create a primitive type that is a proper union type. This would allow us to remove a variant from our enum, as <code>int</code> would simply become a union type with an actual type set.</li> </ol> <pre><code>// Type::Set(1, {})\ntype char;\n// Type::Set(2, { 4 })\ntype int;\n// Type::Set(3, {})\ntype string;\n\n// Type::Set(4, { 4 });\ntype 15;\n\n// Type::Set(4, { 4 }) // same type as `type 15`\nwhere x = 15;\n</code></pre> <p>This would work and also be quite simple to implement.</p>"},{"location":"writeups/0015-ufcs-and-function-calls-rules/","title":"WU0015: UFCS and function resolution rules","text":""},{"location":"writeups/0015-ufcs-and-function-calls-rules/#issue","title":"Issue","text":"<p>We want the language to have UFCS in order to allow \"piping\" of operations without a dedicated piping operator or object system.</p> <p>Therefore, we would like to reuse the \"field access operator\" (<code>.</code>) in order to perform calls as if they were \"method calls\". The simplest form of UFCS is as follows:</p> <pre><code>12.add(15)\n\n// desugars to\nadd(12, 15)\n</code></pre> <p>This is well and good and already implemented in the interpreter. However, the situation gets trickier with modules/multiple compilation units.</p> <p>Let's take the following <code>pair</code> module, which we'll use for the remainder of the writeup.</p> <pre><code>// pair.jk\n\ntype Pair[T](fst: T, snd: T);\n\nfunc pair[T](fst: T, snd: T) -&gt; Pair[T] { Pair(fst: fst, snd: snd) }\n\nfunc map[T](p: Pair[T], f: T -&gt; U) -&gt; Pair[U] {\n    where fst = f(p.fst);\n    where snd = f(p.snd);\n\n    fst.pair(snd)\n}\n</code></pre> <p>We can import that module and make use of it like so:</p> <pre><code>type pair = source[\"pair\"];\n\nwhere p = 1.pair(2); // Pair(1, 2)\nwhere p2 = p.map(x -&gt; x * 2); // Pair(2, 4)\n</code></pre> <p>This code is quite readable, and uses UFCS. This is the sort of code that we would like to \"arrive to\" as the conclusion of this document.</p> <p>However, using \"simple\" UFCS, this is what the above code desugars to:</p> <pre><code>type pair = source[\"pair\"];\n\nwhere p = pair(1, 2);\nwhere p2 = map(p, x -&gt; x * 2);\n</code></pre> <p>As you can see, neither the <code>pair</code> nor the <code>map</code> function exist in the current scope - this should lead to two interpreter errors. A \"simple\" solution is to force the user to \"re-export\" all the functions they will be using through UFCS:</p> <pre><code>type pair = source[\"pair\"];\nwhere map = pair.map;\nwhere pair = pair.pair;\n\nwhere p = 1.pair(2); // Pair(1, 2)\nwhere p2 = p.map(x -&gt; x * 2); // Pair(2, 4)\n</code></pre> <p>But this requires one extra binding per UFCS call, and can quickly get annoying. Without even mentioning binding conflicts and shadowing:</p> <pre><code>type pair = source[\"pair\"];\nwhere map = pair.map;\nwhere pair = pair.pair;\n\nwhere p = 1.pair(2); // Pair(1, 2)\nwhere p2 = p.map(x -&gt; x * 2); // Pair(2, 4)\n\n// now we want to use the `map` function from the `list` module:\n\ntype list = source[\"list\"];\n\nwhere l = [1, 2, 3].map(x -&gt; x * 2);\n</code></pre> <p>The second call to <code>.map()</code> would now resolve to <code>pair.map([1, 2, 3], x -&gt; x * 2)</code>, which would cause a confusing type error for the user - we actually want it to resolve to <code>list.map</code> in that case. An option is to create a new <code>map</code> binding in the source:</p> <pre><code>type pair = source[\"pair\"];\nwhere map = pair.map;\nwhere pair = pair.pair;\n\nwhere p = 1.pair(2); // Pair(1, 2)\nwhere p2 = p.map(x -&gt; x * 2); // Pair(2, 4)\n\n// now we want to use the `map` function from the `list` module:\n\ntype list = source[\"list\"];\nwhere map = list.map;\n\nwhere l = [1, 2, 3].map(x -&gt; x * 2);\n\n// but we want to map pairs again\nwhere psquared = p2.map(x -&gt; x * x);\n</code></pre> <p><code>p2.map(x -&gt; x * x)</code> will now resolve to a call to <code>list.map(p2, x -&gt; x * x)</code>, which is not what the user had in mind either! The only option in that system is to create a binding with a different name for <code>list.map</code>:</p> <pre><code>type pair = source[\"pair\"];\nwhere map = pair.map;\nwhere pair = pair.pair;\n\nwhere p = 1.pair(2); // Pair(1, 2)\nwhere p2 = p.map(x -&gt; x * 2); // Pair(2, 4)\n\n// now we want to use the `map` function from the `list` module:\n\ntype list = source[\"list\"];\nwhere lmap = list.map; // lmap instead of map\n\nwhere l = [1, 2, 3].lmap(x -&gt; x * 2);\n\n// but we want to map pairs again\nwhere psquared = p2.map(x -&gt; x * x);\n</code></pre> <p>Which is... not ergonomic. And confusing! If you were to read someone else's code, you would be confused if they used a different naming convention compared to yours - for exmaple, if they were binding <code>list.map</code> to <code>mapL</code> instead of <code>lmap</code>. This gets worse with more complex functions and function names.</p> <p>The best solution would be for the code to look like this:</p> <pre><code>type pair = source[\"pair\"];\ntype list = source[\"list\"];\n// no re-exports\n\nwhere p = 1.pair(2); // Pair(1, 2)\nwhere p2 = p.map(x -&gt; x * 2); // Pair(2, 4)\n\nwhere l = [1, 2, 3].map(x -&gt; x * 2);\n\nwhere psquared = p2.map(x -&gt; x * x);\n</code></pre> <p>which the type system would desugar appropriately to the following:</p> <pre><code>type pair = source[\"pair\"];\ntype list = source[\"list\"];\n// no re-exports\n\nwhere p = pair.pair(1, 2); // Pair(1, 2)\nwhere p2 = pair.map(p, x -&gt; x * 2); // Pair(2, 4)\n\nwhere l = list.map([1, 2, 3], x -&gt; x * 2);\n\nwhere psquared = pair.map(p2, x -&gt; x * x);\n</code></pre>"},{"location":"writeups/0015-ufcs-and-function-calls-rules/#proposed-solution","title":"Proposed solution","text":"<ol> <li>Have more complex method resolution rules than just UFCS</li> <li>Allow it to resolve to default members of types?</li> <li>How do we restrict this so that it creates no ambiguities and makes sense?</li> <li>What if it resolves to a binding's field instead? that must make for some pretty confusing errors</li> </ol> <p>The TL;DR is as follows:</p> <p>Allow UFCS to desugar <code>x.foo()</code> to <code>foo(x)</code> OR <code>_.foo(x)</code></p> <p>with <code>_</code> being any binding or type in the current namespace.</p> <p>In the case of an ambiguity, emit a hard error.</p>"},{"location":"writeups/0015-ufcs-and-function-calls-rules/#drawbacks","title":"Drawbacks","text":"<ol> <li>Resolving to a binding's field instead of a module function</li> </ol> <pre><code>// int.jk\nfunc add(lhs: int, rhs: int) -&gt; int { lhs + rhs }\n\n// main.jk\ntype int = source[\"int\"];\n\ntype Random(add: (int, int) -&gt; int);\n\nfunc sub(lhs: int, rhs: int) -&gt; int { lhs - rhs }\n\nwhere random_binding = Random(add: sub); // !!\n\n12.add(15);\n</code></pre> <p>If we do allow resolving to binding's fields and type fields and functions that exist in the current namespace, then this could resolve to either of the following:</p> <ul> <li><code>int.add</code></li> <li><code>random_binding.add</code>, which is actually the <code>sub</code> function.</li> </ul> <p>What to do in that case? What can the user do? We can definitely error on ambiguities, but surely this would incur complexity for users.</p>"},{"location":"writeups/0015-ufcs-and-function-calls-rules/#proposed-solution-2","title":"Proposed solution 2","text":"<p>Skip UFCS and instead introduce a piping operator.</p> <pre><code>type pair = source[\"pair\"];\ntype list = source[\"list\"];\n\nwhere p = 1 |&gt; pair.pair(2);\nwhere p2 = p |&gt; pair.map(x -&gt; x *2);\n\nwhere l = [1, 2, 3] |&gt; list.map(x -&gt; x * 2);\n\nwhere psquared = p2 |&gt; pair.map(x -&gt; x * x)\n</code></pre> <p>This syntax is however very heavy for what should be a small typed scripting language.</p>"}]}